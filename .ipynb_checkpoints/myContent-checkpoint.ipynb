{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e162353-342b-4757-8a5b-a19043123c51",
   "metadata": {},
   "source": [
    "# My Content — MVP Recommandation\n",
    "\n",
    "## Contexte\n",
    "My Content veut encourager la lecture en recommandant des contenus pertinents.  \n",
    "Nous développons un premier MVP basé sur un dataset public de logs de navigation (clics), sessions utilisateurs, métadonnées et embeddings d’articles (dataset Globo/G1 utilisé dans les travaux CHAMELEON).\n",
    "\n",
    "## Objectif MVP\n",
    "**En tant qu’utilisateur, je reçois une sélection de cinq articles.**\n",
    "\n",
    "Le MVP doit démontrer :\n",
    "- qu’on peut recommander **sans données internes** (avec le dataset public),\n",
    "- qu’on peut gérer le **cold start** (nouveaux utilisateurs) et l’arrivée de **nouveaux articles**,\n",
    "- qu’on peut **déployer** la solution (Azure Function + interface simple).\n",
    "\n",
    "## Approche du notebook\n",
    "Nous commençons par une baseline **transparente et métier**, facile à expliquer et à déployer :\n",
    "- **Trending** : recommander les articles les plus consultés (fallback cold start user),\n",
    "- **Item-Item co-clic** : recommander des articles “souvent lus ensemble” dans les sessions (personnalisation légère).\n",
    "\n",
    "Ensuite, nous mettrons en place un protocole d’évaluation **top-K** (ex. HR@5, MRR@5) adapté aux données implicites, puis nous discuterons l’extension vers une approche hybride exploitant davantage les embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb78f22-45e2-4099-8804-81bcb91fc76f",
   "metadata": {},
   "source": [
    "## Imports & configuration\n",
    "\n",
    "Cette cellule prépare l’environnement de travail :\n",
    "- import des bibliothèques (pandas/numpy),\n",
    "- définition des chemins vers les fichiers du dataset (clics, métadonnées, embeddings),\n",
    "- définition des constantes du MVP (TOP_K, seed),\n",
    "- standardisation des noms de colonnes attendues (user, session, item, timestamp).\n",
    "\n",
    "Objectif : avoir une base stable et lisible avant de charger les données et construire la baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d9b899-9ce6-4668-93a4-83b48803b56e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config OK\n",
      "Clicks dir: data/clicks\n",
      "Meta path: data/articles_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports + config (baseline transparente)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inspect\n",
    "\n",
    "# Chemins (à adapter)\n",
    "DATA_DIR = \"data\"  # ex: dossier où tu as dézippé clicks.zip + metadata + embeddings\n",
    "CLICKS_DIR = os.path.join(DATA_DIR, \"clicks\")  # dossier avec les CSV par heure\n",
    "ARTICLES_META_PATH = os.path.join(DATA_DIR, \"articles_metadata.csv\")\n",
    "EMBEDDINGS_PATH = os.path.join(DATA_DIR, \"articles_embeddings.pickle\")  # optionnel pour plus tard\n",
    "\n",
    "# Paramètres MVP\n",
    "TOP_K = 5\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Colonnes principales (dataset CHAMELEON)\n",
    "COL_USER = \"user_id\"\n",
    "COL_SESSION = \"session_id\"\n",
    "COL_ITEM = \"click_article_id\"\n",
    "COL_TS = \"click_timestamp\"  # timestamp du clic (ms)\n",
    "\n",
    "print(\"Config OK\")\n",
    "print(\"Clicks dir:\", CLICKS_DIR)\n",
    "print(\"Meta path:\", ARTICLES_META_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff5098-a4bc-4b0f-91b1-8f285d584cf2",
   "metadata": {},
   "source": [
    "## Lister les fichiers de clics et estimer le volume\n",
    "\n",
    "Objectifs :\n",
    "- lister tous les fichiers `clicks` (CSV par heure),\n",
    "- estimer le volume total (nombre de fichiers, taille disque),\n",
    "- afficher un aperçu (plus gros fichiers, taille moyenne).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0c9f75-1427-4f98-b93c-afcd94391a0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers: 385\n",
      "Taille totale: 0.21 GB\n",
      "Taille moyenne: 0.55 MB | médiane: 0.45 MB | min: 0.00 MB | max: 2.01 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clicks_hour_224.csv</td>\n",
       "      <td>2.013713</td>\n",
       "      <td>data/clicks/clicks_hour_224.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clicks_hour_041.csv</td>\n",
       "      <td>1.685356</td>\n",
       "      <td>data/clicks/clicks_hour_041.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clicks_hour_225.csv</td>\n",
       "      <td>1.515978</td>\n",
       "      <td>data/clicks/clicks_hour_225.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clicks_hour_043.csv</td>\n",
       "      <td>1.503445</td>\n",
       "      <td>data/clicks/clicks_hour_043.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clicks_hour_037.csv</td>\n",
       "      <td>1.500683</td>\n",
       "      <td>data/clicks/clicks_hour_037.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clicks_hour_226.csv</td>\n",
       "      <td>1.449932</td>\n",
       "      <td>data/clicks/clicks_hour_226.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clicks_hour_042.csv</td>\n",
       "      <td>1.426556</td>\n",
       "      <td>data/clicks/clicks_hour_042.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clicks_hour_036.csv</td>\n",
       "      <td>1.414001</td>\n",
       "      <td>data/clicks/clicks_hour_036.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clicks_hour_201.csv</td>\n",
       "      <td>1.392688</td>\n",
       "      <td>data/clicks/clicks_hour_201.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clicks_hour_227.csv</td>\n",
       "      <td>1.387267</td>\n",
       "      <td>data/clicks/clicks_hour_227.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file   size_mb                             path\n",
       "0  clicks_hour_224.csv  2.013713  data/clicks/clicks_hour_224.csv\n",
       "1  clicks_hour_041.csv  1.685356  data/clicks/clicks_hour_041.csv\n",
       "2  clicks_hour_225.csv  1.515978  data/clicks/clicks_hour_225.csv\n",
       "3  clicks_hour_043.csv  1.503445  data/clicks/clicks_hour_043.csv\n",
       "4  clicks_hour_037.csv  1.500683  data/clicks/clicks_hour_037.csv\n",
       "5  clicks_hour_226.csv  1.449932  data/clicks/clicks_hour_226.csv\n",
       "6  clicks_hour_042.csv  1.426556  data/clicks/clicks_hour_042.csv\n",
       "7  clicks_hour_036.csv  1.414001  data/clicks/clicks_hour_036.csv\n",
       "8  clicks_hour_201.csv  1.392688  data/clicks/clicks_hour_201.csv\n",
       "9  clicks_hour_227.csv  1.387267  data/clicks/clicks_hour_227.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Cellule — Listing + estimation volume (taille disque)\n",
    "\n",
    "click_files = sorted(glob.glob(os.path.join(CLICKS_DIR, \"*.csv\")))\n",
    "if len(click_files) == 0:\n",
    "    raise FileNotFoundError(f\"Aucun fichier .csv trouvé dans {CLICKS_DIR}\")\n",
    "\n",
    "sizes_bytes = np.array([os.path.getsize(p) for p in click_files], dtype=np.int64)\n",
    "\n",
    "total_gb = sizes_bytes.sum() / (1024**3)\n",
    "mean_mb = sizes_bytes.mean() / (1024**2)\n",
    "median_mb = np.median(sizes_bytes) / (1024**2)\n",
    "min_mb = sizes_bytes.min() / (1024**2)\n",
    "max_mb = sizes_bytes.max() / (1024**2)\n",
    "\n",
    "print(f\"Nombre de fichiers: {len(click_files)}\")\n",
    "print(f\"Taille totale: {total_gb:.2f} GB\")\n",
    "print(f\"Taille moyenne: {mean_mb:.2f} MB | médiane: {median_mb:.2f} MB | min: {min_mb:.2f} MB | max: {max_mb:.2f} MB\")\n",
    "\n",
    "# Affiche les 10 plus gros fichiers\n",
    "top_n = 10\n",
    "idx = np.argsort(-sizes_bytes)[:top_n]\n",
    "top_df = pd.DataFrame({\n",
    "    \"file\": [os.path.basename(click_files[i]) for i in idx],\n",
    "    \"size_mb\": [sizes_bytes[i] / (1024**2) for i in idx],\n",
    "    \"path\": [click_files[i] for i in idx],\n",
    "})\n",
    "display(top_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e380ac9-de67-4c29-82d7-ad04f0050db2",
   "metadata": {},
   "source": [
    "## Chargement d’un échantillon de logs de clics (sanity check)\n",
    "\n",
    "Objectifs :\n",
    "- vérifier que les fichiers de clics sont bien accessibles (CSV par heure),\n",
    "- charger un petit échantillon pour inspecter les colonnes et types,\n",
    "- valider la présence des colonnes clés (user, session, article, timestamp),\n",
    "- avoir un premier aperçu de la période (min/max timestamp) et du volume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b87454-a3b6-4416-a095-9208aaccba1c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers de clics trouvés: 385\n",
      "Exemples: ['data/clicks/clicks_hour_000.csv', 'data/clicks/clicks_hour_001.csv', 'data/clicks/clicks_hour_002.csv']\n",
      "\n",
      "Fichier échantillon: clicks_hour_000.csv\n",
      "Shape: (1883, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_size</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>157541</td>\n",
       "      <td>1506826828020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>68866</td>\n",
       "      <td>1506826858020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>235840</td>\n",
       "      <td>1506827017951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>96663</td>\n",
       "      <td>1506827047951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1506825435299739</td>\n",
       "      <td>1506825435000</td>\n",
       "      <td>2</td>\n",
       "      <td>119592</td>\n",
       "      <td>1506827090575</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        session_id  session_start  session_size  click_article_id  \\\n",
       "0        0  1506825423271737  1506825423000             2            157541   \n",
       "1        0  1506825423271737  1506825423000             2             68866   \n",
       "2        1  1506825426267738  1506825426000             2            235840   \n",
       "3        1  1506825426267738  1506825426000             2             96663   \n",
       "4        2  1506825435299739  1506825435000             2            119592   \n",
       "\n",
       "   click_timestamp  click_environment  click_deviceGroup  click_os  \\\n",
       "0    1506826828020                  4                  3        20   \n",
       "1    1506826858020                  4                  3        20   \n",
       "2    1506827017951                  4                  1        17   \n",
       "3    1506827047951                  4                  1        17   \n",
       "4    1506827090575                  4                  1        17   \n",
       "\n",
       "   click_country  click_region  click_referrer_type  \n",
       "0              1            20                    2  \n",
       "1              1            20                    2  \n",
       "2              1            16                    2  \n",
       "3              1            16                    2  \n",
       "4              1            24                    2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Colonnes: ['user_id', 'session_id', 'session_start', 'session_size', 'click_article_id', 'click_timestamp', 'click_environment', 'click_deviceGroup', 'click_os', 'click_country', 'click_region', 'click_referrer_type']\n",
      "\n",
      "Dtypes:\n",
      " user_id                int64\n",
      "session_id             int64\n",
      "session_start          int64\n",
      "session_size           int64\n",
      "click_article_id       int64\n",
      "click_timestamp        int64\n",
      "click_environment      int64\n",
      "click_deviceGroup      int64\n",
      "click_os               int64\n",
      "click_country          int64\n",
      "click_region           int64\n",
      "click_referrer_type    int64\n",
      "dtype: object\n",
      "\n",
      "Colonnes manquantes: set()\n",
      "\n",
      "Période (échantillon) :\n",
      " - min: 2017-10-01 03:00:00.026000\n",
      " - max: 2017-10-03 02:35:54.157000\n",
      " - % NaT: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lister les fichiers + charger un échantillon\n",
    "\n",
    "click_files = sorted(glob.glob(os.path.join(CLICKS_DIR, \"*.csv\")))\n",
    "print(f\"Nombre de fichiers de clics trouvés: {len(click_files)}\")\n",
    "print(\"Exemples:\", click_files[:3])\n",
    "\n",
    "# Charge un seul fichier (petit) pour inspection\n",
    "sample_path = click_files[0]\n",
    "clicks_sample = pd.read_csv(sample_path)\n",
    "\n",
    "print(\"\\nFichier échantillon:\", os.path.basename(sample_path))\n",
    "print(\"Shape:\", clicks_sample.shape)\n",
    "display(clicks_sample.head())\n",
    "\n",
    "print(\"\\nColonnes:\", list(clicks_sample.columns))\n",
    "print(\"\\nDtypes:\\n\", clicks_sample.dtypes)\n",
    "\n",
    "# Vérifie que les colonnes attendues existent\n",
    "required_cols = {COL_USER, COL_SESSION, COL_ITEM, COL_TS}\n",
    "missing = required_cols - set(clicks_sample.columns)\n",
    "print(\"\\nColonnes manquantes:\", missing)\n",
    "\n",
    "# Aperçu rapide des timestamps (si colonne présente)\n",
    "if COL_TS in clicks_sample.columns:\n",
    "    ts = pd.to_datetime(clicks_sample[COL_TS], unit=\"ms\", errors=\"coerce\")\n",
    "    print(\"\\nPériode (échantillon) :\")\n",
    "    print(\" - min:\", ts.min())\n",
    "    print(\" - max:\", ts.max())\n",
    "    print(\" - % NaT:\", ts.isna().mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06041a-0fe9-4969-85ed-3704389c885f",
   "metadata": {},
   "source": [
    "## Charger un sous-ensemble “train/test” (split temporel simple)\n",
    "\n",
    "Objectif :\n",
    "- Charger un bloc de fichiers horaires pour itérer vite (ex: N heures pour train, M heures pour test).\n",
    "- Construire un split réaliste basé sur le temps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb7c35db-4956-4c48-95f1-9a59cc764596",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (118339, 4)\n",
      "Test shape : (13216, 4)\n",
      "Train ts: 2017-10-01 03:00:00.026000 -> 2017-10-24 23:48:51.578000\n",
      "Test  ts: 2017-10-02 02:36:25.019000 -> 2017-10-11 05:33:25.108000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charge une fenêtre temporelle (par nombre de fichiers)\n",
    "# Ajuste N_TRAIN_FILES / N_TEST_FILES selon la puissance de ta machine.\n",
    "\n",
    "N_TRAIN_FILES = 24\n",
    "N_TEST_FILES = 6\n",
    "\n",
    "click_files = sorted(glob.glob(os.path.join(CLICKS_DIR, \"*.csv\")))\n",
    "train_files = click_files[:N_TRAIN_FILES]\n",
    "test_files = click_files[N_TRAIN_FILES:N_TRAIN_FILES + N_TEST_FILES]\n",
    "\n",
    "def load_clicks(files: list[str]) -> pd.DataFrame:\n",
    "    # Charge une liste de CSV et garde uniquement les colonnes utiles à la baseline.\n",
    "    dfs = []\n",
    "    for p in files:\n",
    "        df = pd.read_csv(p)\n",
    "        dfs.append(df[[COL_USER, COL_SESSION, COL_ITEM, COL_TS]])\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "clicks_train = load_clicks(train_files)\n",
    "clicks_test = load_clicks(test_files)\n",
    "\n",
    "print(\"Train shape:\", clicks_train.shape)\n",
    "print(\"Test shape :\", clicks_test.shape)\n",
    "\n",
    "# Conversion timestamp en datetime pour tri et contrôles\n",
    "clicks_train[\"ts\"] = pd.to_datetime(clicks_train[COL_TS], unit=\"ms\", errors=\"coerce\")\n",
    "clicks_test[\"ts\"] = pd.to_datetime(clicks_test[COL_TS], unit=\"ms\", errors=\"coerce\")\n",
    "\n",
    "print(\"Train ts:\", clicks_train[\"ts\"].min(), \"->\", clicks_train[\"ts\"].max())\n",
    "print(\"Test  ts:\", clicks_test[\"ts\"].min(), \"->\", clicks_test[\"ts\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8148552-cfd9-48a4-a244-1cf3df5e3817",
   "metadata": {},
   "source": [
    "## Préparation des données (nettoyage minimal)\n",
    "\n",
    "Objectifs :\n",
    "- supprimer les lignes invalides (ids manquants, timestamp invalide),\n",
    "- garantir les types (int),\n",
    "- trier les clics dans chaque session (ordre chronologique),\n",
    "- enlever les doublons (même article dans la même session).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fb69eb-2233-4886-9636-be3c9892248c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train prepared: (118339, 5)\n",
      "Test prepared : (13216, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>157541</td>\n",
       "      <td>1506826828020</td>\n",
       "      <td>2017-10-01 03:00:28.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>68866</td>\n",
       "      <td>1506826858020</td>\n",
       "      <td>2017-10-01 03:00:58.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>235840</td>\n",
       "      <td>1506827017951</td>\n",
       "      <td>2017-10-01 03:03:37.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>96663</td>\n",
       "      <td>1506827047951</td>\n",
       "      <td>2017-10-01 03:04:07.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1506825435299739</td>\n",
       "      <td>119592</td>\n",
       "      <td>1506827090575</td>\n",
       "      <td>2017-10-01 03:04:50.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        session_id  click_article_id  click_timestamp  \\\n",
       "0        0  1506825423271737            157541    1506826828020   \n",
       "1        0  1506825423271737             68866    1506826858020   \n",
       "2        1  1506825426267738            235840    1506827017951   \n",
       "3        1  1506825426267738             96663    1506827047951   \n",
       "4        2  1506825435299739            119592    1506827090575   \n",
       "\n",
       "                       ts  \n",
       "0 2017-10-01 03:00:28.020  \n",
       "1 2017-10-01 03:00:58.020  \n",
       "2 2017-10-01 03:03:37.951  \n",
       "3 2017-10-01 03:04:07.951  \n",
       "4 2017-10-01 03:04:50.575  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Préparation des données, nettoyage\n",
    "\n",
    "def prepare_clicks(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Garde uniquement les lignes exploitables\n",
    "    x = df.dropna(subset=[COL_USER, COL_SESSION, COL_ITEM, \"ts\"]).copy()\n",
    "\n",
    "    # Types stables\n",
    "    x[COL_USER] = x[COL_USER].astype(int)\n",
    "    x[COL_SESSION] = x[COL_SESSION].astype(int)\n",
    "    x[COL_ITEM] = x[COL_ITEM].astype(int)\n",
    "\n",
    "    # Tri chronologique dans chaque session (utile pour next-click)\n",
    "    x = x.sort_values([COL_SESSION, \"ts\"], ascending=[True, True])\n",
    "\n",
    "    # Un article ne doit compter qu'une fois par session\n",
    "    x = x.drop_duplicates(subset=[COL_SESSION, COL_ITEM], keep=\"first\")\n",
    "    return x\n",
    "\n",
    "clicks_train_p = prepare_clicks(clicks_train)\n",
    "clicks_test_p = prepare_clicks(clicks_test)\n",
    "\n",
    "print(\"Train prepared:\", clicks_train_p.shape)\n",
    "print(\"Test prepared :\", clicks_test_p.shape)\n",
    "display(clicks_train_p.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3380a368-8151-458b-a474-e84a00157799",
   "metadata": {},
   "source": [
    "## Baseline : Trending (popularité)\n",
    "\n",
    "Objectifs :\n",
    "- calculer les articles les plus cliqués dans le train,\n",
    "- servir ces articles comme recommandation pour tout le monde (cold start).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10728a0-3f4f-4794-9b05-34e475c399d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>272660</td>\n",
       "      <td>7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207122</td>\n",
       "      <td>7347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161178</td>\n",
       "      <td>6660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284463</td>\n",
       "      <td>6497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160474</td>\n",
       "      <td>5020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59758</td>\n",
       "      <td>4565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>313504</td>\n",
       "      <td>4469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>119592</td>\n",
       "      <td>4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>96663</td>\n",
       "      <td>4245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>235132</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  score\n",
       "0      272660   7742\n",
       "1      207122   7347\n",
       "2      161178   6660\n",
       "3      284463   6497\n",
       "4      160474   5020\n",
       "5       59758   4565\n",
       "6      313504   4469\n",
       "7      119592   4410\n",
       "8       96663   4245\n",
       "9      235132   3215"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Trending pour la baseline\n",
    "\n",
    "def build_trending(df_train: pd.DataFrame, top_n: int = 2000) -> pd.DataFrame:\n",
    "    # Compte les clics par article et garde les plus populaires\n",
    "    vc = df_train[COL_ITEM].value_counts().head(top_n)\n",
    "    trending_df = vc.rename_axis(\"article_id\").reset_index(name=\"score\")\n",
    "    trending_df[\"article_id\"] = trending_df[\"article_id\"].astype(int)\n",
    "    return trending_df\n",
    "\n",
    "trending = build_trending(clicks_train_p, top_n=2000)\n",
    "display(trending.head(10))\n",
    "\n",
    "# Liste utilisée par le recommender\n",
    "TRENDING_LIST = trending[\"article_id\"].tolist()\n",
    "\n",
    "def recommend_trending(k: int = TOP_K) -> list[int]:\n",
    "    # Retourne les K articles les plus populaires\n",
    "    return TRENDING_LIST[:k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b2466-0567-4831-9465-f9fcd924a144",
   "metadata": {},
   "source": [
    "## Baseline : Item-Item co-clic (voisins par article)\n",
    "\n",
    "Objectifs :\n",
    "- construire, à partir du train, les articles souvent vus dans la même session,\n",
    "- produire une table `article_id -> top voisins`,\n",
    "- proposer des recommandations personnalisées à partir des derniers amrticles vus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37250e31-33d3-4459-9160-650442818920",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>neighbor_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>co_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271</td>\n",
       "      <td>205420</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>331293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388</td>\n",
       "      <td>239459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>683</td>\n",
       "      <td>313504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1916</td>\n",
       "      <td>59758</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1916</td>\n",
       "      <td>64329</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1916</td>\n",
       "      <td>95524</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1916</td>\n",
       "      <td>95633</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1916</td>\n",
       "      <td>118751</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1916</td>\n",
       "      <td>156229</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  neighbor_id  rank  co_count\n",
       "0         271       205420     1         1\n",
       "1         290       331293     1         1\n",
       "2         388       239459     1         1\n",
       "3         683       313504     1         1\n",
       "4        1916        59758     1         1\n",
       "5        1916        64329     2         1\n",
       "6        1916        95524     3         1\n",
       "7        1916        95633     4         1\n",
       "8        1916       118751     5         1\n",
       "9        1916       156229     6         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Item-Item-Co-Click - Recommend from history\n",
    "\n",
    "# Construit une table item-item basée sur la co-occurrence en session:\n",
    "# - article_id = article source\n",
    "# - neighbor_id = article souvent vu avec l'article source\n",
    "# - co_count = nombre de sessions où ils co-apparaissent\n",
    "# - rank = position du voisin (1 = meilleur)\n",
    "\n",
    "def build_item_item_coclick(df_train: pd.DataFrame, k_neighbors: int = 100) -> pd.DataFrame:\n",
    "    # On ne garde que session + article\n",
    "    sess_items = df_train[[COL_SESSION, COL_ITEM]].copy()\n",
    "    sess_items = sess_items.rename(columns={COL_SESSION: \"session_id\", COL_ITEM: \"article_id\"})\n",
    "\n",
    "    # Sécurité: un article ne compte qu'une fois par session\n",
    "    sess_items = sess_items.drop_duplicates(subset=[\"session_id\", \"article_id\"], keep=\"first\")\n",
    "\n",
    "    # Auto-join par session pour obtenir toutes les paires co-cliquées (a,b)\n",
    "    left = sess_items.rename(columns={\"article_id\": \"a\"})\n",
    "    right = sess_items.rename(columns={\"article_id\": \"b\"})\n",
    "    pairs = left.merge(right, on=\"session_id\", how=\"inner\")\n",
    "\n",
    "    # On enlève les paires identiques (a == b)\n",
    "    pairs = pairs[pairs[\"a\"] != pairs[\"b\"]]\n",
    "\n",
    "    # Compte de co-occurrence: nombre de sessions contenant (a,b)\n",
    "    counts = (\n",
    "        pairs.groupby([\"a\", \"b\"], as_index=False)\n",
    "        .size()\n",
    "        .rename(columns={\"size\": \"co_count\"})\n",
    "    )\n",
    "\n",
    "    # Top voisins par article a\n",
    "    counts = counts.sort_values([\"a\", \"co_count\"], ascending=[True, False])\n",
    "    counts[\"rank\"] = counts.groupby(\"a\").cumcount() + 1\n",
    "    topk = counts[counts[\"rank\"] <= k_neighbors].copy()\n",
    "\n",
    "    # Format standard\n",
    "    item_item_df = topk.rename(columns={\"a\": \"article_id\", \"b\": \"neighbor_id\"})\n",
    "    return item_item_df[[\"article_id\", \"neighbor_id\", \"rank\", \"co_count\"]]\n",
    "\n",
    "# Construction de la table item-item\n",
    "item_item = build_item_item_coclick(clicks_train_p, k_neighbors=100)\n",
    "display(item_item.head(10))\n",
    "\n",
    "# Dictionnaire: article_id -> liste des voisins (par ordre de rank)\n",
    "neighbors_map = (\n",
    "    item_item.sort_values([\"article_id\", \"rank\"])\n",
    "    .groupby(\"article_id\")[\"neighbor_id\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "def recommend_item_item_from_history(history: list[int], k: int = TOP_K) -> list[int]:\n",
    "    # Agrège les voisins des derniers articles vus.\n",
    "    # Score simple: somme(1/rank) pour les voisins proposés.\n",
    "    scores = {}\n",
    "    seen = set(history)\n",
    "\n",
    "    for item in history[-5:]:\n",
    "        for rank, neigh in enumerate(neighbors_map.get(item, []), start=1):\n",
    "            if neigh in seen:\n",
    "                continue\n",
    "            scores[neigh] = scores.get(neigh, 0.0) + (1.0 / rank)\n",
    "\n",
    "    ranked = [aid for aid, _ in sorted(scores.items(), key=lambda t: t[1], reverse=True)]\n",
    "\n",
    "    # Complète avec trending si nécessaire\n",
    "    out = []\n",
    "    for aid in ranked:\n",
    "        if aid not in out:\n",
    "            out.append(aid)\n",
    "        if len(out) >= k:\n",
    "            return out\n",
    "\n",
    "    for aid in TRENDING_LIST:\n",
    "        if aid not in out and aid not in seen:\n",
    "            out.append(aid)\n",
    "        if len(out) >= k:\n",
    "            break\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe71d0-aa7e-4d42-a343-571d056855ee",
   "metadata": {},
   "source": [
    "## Où on en est (baseline recommandation)\n",
    "\n",
    "À ce stade, on a construit deux stratégies simples à partir des clics du **train** :\n",
    "\n",
    "### 1) Trending (popularité)\n",
    "- On compte combien de fois chaque article a été cliqué dans le train.\n",
    "- On trie du plus cliqué au moins cliqué.\n",
    "- On recommande les **K** premiers à tout le monde.\n",
    "- Utilité : **fallback** quand on ne sait rien sur l’utilisateur (cold start user).\n",
    "\n",
    "### 2) Item-Item co-clic (articles “souvent vus ensemble”)\n",
    "**Item = article**, et **co-clic = co-occurrence dans une même session**.\n",
    "\n",
    "Exemple de sessions (paniers) :\n",
    "- S1 : [A, B, C]\n",
    "- S2 : [A, B]\n",
    "- S3 : [A, D]\n",
    "\n",
    "On en déduit que :\n",
    "- A est souvent associé à B → B est un bon candidat à recommander après A.\n",
    "\n",
    "### Ce que représente `item_item_coclick` vs `item_item`\n",
    "- `item_item_coclick` : la **méthode** (calculer des voisinages à partir des co-clics en session).\n",
    "- `item_item` : le **résultat** (une table / DataFrame) avec, pour chaque article, ses voisins.\n",
    "\n",
    "Chaque ligne de `item_item` contient typiquement :\n",
    "- `article_id` : l’article “source” (ex: A)\n",
    "- `neighbor_id` : un article “voisin” (ex: B)\n",
    "- `co_count` : nombre de sessions où A et B apparaissent ensemble\n",
    "- `rank` : position de B parmi les voisins de A (1 = meilleur voisin)\n",
    "\n",
    "Autrement dit :\n",
    "> `item_item` = “pour chaque article, les meilleurs articles associés selon les sessions”.\n",
    "\n",
    "### Comment on recommande pour un utilisateur\n",
    "1) On récupère l’historique récent de l’utilisateur (ex: [A, C]).\n",
    "2) On prend les voisins de A et les voisins de C (via `item_item`).\n",
    "3) On fusionne, on enlève les doublons et les articles déjà vus.\n",
    "4) On garde les **K** meilleurs candidats.\n",
    "5) S’il manque des articles, on complète avec **Trending**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcedbaeb-a519-43c0-9908-a289efc08483",
   "metadata": {},
   "source": [
    "## Évaluation simple (next-click) : HR@5 et MRR@5\n",
    "\n",
    "Objectif :\n",
    "- simuler une recommandation en cours de session,\n",
    "- comparer deux baselines : Trending vs Item-Item co-clic,\n",
    "- calculer :\n",
    "  - **HR@5** : le prochain clic est-il dans le top-5 ?\n",
    "  - **MRR@5** : s’il y est, est-il plutôt en haut de la liste ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9146ffa8-2fd7-4ea6-993e-12b1dce12198",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Helpers métriques: HR@k et MRR@k\n",
    "def hr_mrr_at_k(true_item: int, recs: list[int], k: int = TOP_K) -> tuple[float, float]:\n",
    "    # HR@k = 1 si vrai item dans top-k, sinon 0\n",
    "    # MRR@k = 1/rang si présent, sinon 0\n",
    "    topk = recs[:k]\n",
    "    if true_item in topk:\n",
    "        rank = topk.index(true_item) + 1\n",
    "        return 1.0, 1.0 / rank\n",
    "    return 0.0, 0.0\n",
    "\n",
    "\n",
    "# Évaluation next-click (version 2 : compatible baselines ET modèles user-aware)\n",
    "# - On cache le dernier item de chaque session\n",
    "# - On recommande top-k\n",
    "# - On calcule HR@k et MRR@k\n",
    "#\n",
    "# Compatible avec 2 signatures de recommend_fn :\n",
    "#   1) recommend_fn(history, k)\n",
    "#   2) recommend_fn(user_id, history, k)\n",
    "\n",
    "def evaluate_next_click(\n",
    "    # On évalue sur des sessions de test : pour chaque session, on prend un préfixe et on prédit le prochain clic.\n",
    "    # On utilise ici \"dernier préfixe\" : on donne tous les clics sauf le dernier, et on essaie de deviner le dernier.\n",
    "    df_test: pd.DataFrame,\n",
    "    recommend_fn,\n",
    "    k: int = TOP_K,\n",
    "    max_sessions: int = 5000,\n",
    "    col_user: str = \"user_id\",\n",
    "    col_session: str = \"session_id\",\n",
    "    col_item: str = \"click_article_id\",\n",
    "    col_ts: str = \"click_timestamp\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Évaluation next-click:\n",
    "    - on cache le dernier item d’une session\n",
    "    - on recommande\n",
    "    - on calcule HR@k / MRR@k\n",
    "    - on conserve aussi la stratégie utilisée (lightfm / trending)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    n_done = 0\n",
    "\n",
    "    # Détecte si recommend_fn attend (user_id, history, k) ou (history, k)\n",
    "    n_params = len(inspect.signature(recommend_fn).parameters)\n",
    "\n",
    "    for session_id, g in df_test.groupby(col_session):\n",
    "        # Besoin d'au moins 2 clics pour faire un \"next-click\"\n",
    "        if len(g) < 2:\n",
    "            continue\n",
    "\n",
    "        # Ordonne chronologiquement la session\n",
    "        g = g.sort_values(col_ts)\n",
    "\n",
    "        # user_id (constant dans la session)\n",
    "        user_id = int(g.iloc[0][col_user])\n",
    "\n",
    "        # Séquence d’items\n",
    "        items = g[col_item].astype(int).tolist()\n",
    "        history = items[:-1]\n",
    "        true_next = int(items[-1])\n",
    "\n",
    "        # Appel recommandé (2 signatures possibles)\n",
    "        if n_params >= 3:\n",
    "            recs_out = recommend_fn(user_id, history, k)\n",
    "        else:\n",
    "            recs_out = recommend_fn(history, k)\n",
    "\n",
    "        # Supporte recs seuls OU (recs, strategy)\n",
    "        if isinstance(recs_out, tuple) and len(recs_out) == 2:\n",
    "            recs, strategy = recs_out\n",
    "        else:\n",
    "            recs, strategy = recs_out, \"unknown\"\n",
    "\n",
    "        # Calcule métriques\n",
    "        hr, mrr = hr_mrr_at_k(true_next, recs, k=k)\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"session_id\": int(session_id),\n",
    "                \"user_id\": user_id,\n",
    "                \"true_next\": true_next,\n",
    "                f\"HR@{k}\": hr,\n",
    "                f\"MRR@{k}\": mrr,\n",
    "                \"strategy\": strategy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        n_done += 1\n",
    "        if n_done >= max_sessions:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Wrappers pour unifier les signatures (history, k)\n",
    "def recommend_trending_from_history(history: list[int], k: int = TOP_K) -> list[int]:\n",
    "    return recommend_trending(k=k)\n",
    "\n",
    "def recommend_coclick_from_history(history: list[int], k: int = TOP_K) -> list[int]:\n",
    "    return recommend_item_item_from_history(history, k=k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6688d-67dd-49ea-b241-d1e04326f607",
   "metadata": {},
   "source": [
    "## les premiers modèles\n",
    "\n",
    "À ce stade, on a bien **2 baselines**, et la cellule sert uniquement à **les comparer**.\n",
    "\n",
    "### Modèle 1 - Baseline — Trending (popularité)\n",
    "- Même 5 articles pour tout le monde : les plus cliqués dans le train.\n",
    "- Sert de **plancher** : “au minimum, recommander les articles populaires, ça donne quoi ?”.\n",
    "\n",
    "### Modèle 2 — Item-Item co-clic (personnalisation simple)\n",
    "- À partir des derniers articles cliqués dans une session, on recommande des articles **souvent co-cliqués** avec eux.\n",
    "- Sert de baseline “un cran au-dessus”, tout en restant **très transparente**.\n",
    "\n",
    "### Ce que fait la cellule d’évaluation\n",
    "1) Elle lance `evaluate_next_click(...)` avec la baseline **Trending** → on obtient HR@5 et MRR@5 sur des sessions de test.\n",
    "2) Elle relance la même évaluation avec la baseline **co-clic**.\n",
    "3) Elle calcule les moyennes et affiche un **résumé** pour comparer les deux.\n",
    "\n",
    "### Pourquoi on le fait maintenant\n",
    "Cela permet de dire clairement dans le projet :\n",
    "- “La baseline popularité fait X”\n",
    "- “La baseline co-clic fait Y”\n",
    "- “Donc notre approche apporte (ou non) un gain”\n",
    "\n",
    "Et ça aide à décider si ça vaut le coup de passer ensuite à une approche plus avancée (embeddings/LightFM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4aeb87-7a54-48f7-b80f-2659bcf88b22",
   "metadata": {},
   "source": [
    "### Clarification\n",
    "\n",
    "- Réalité (ground truth) : l’article réellement cliqué ensuite (dans le test).\n",
    "- Trending : prédiction naïve basée sur la popularité globale.\n",
    "- Co-clic : prédiction plus personnalisée basée sur les associations d’articles en session.\n",
    "\n",
    "On compare les prédictions de chaque baseline à la réalité, avec HR@5 / MRR@5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb96eb4-96a3-4658-a06b-a24df2325dd0",
   "metadata": {},
   "source": [
    "## Lancer l’évaluation : Trending vs Co-clic\n",
    "\n",
    "Objectif :\n",
    "- obtenir un score moyen HR@5 et MRR@5 sur un échantillon de sessions test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86ac2cc0-487d-4efc-940b-8a5fd2b47dcf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>MRR@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trending</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.175449</td>\n",
       "      <td>0.114560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item-Item co-clic</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.399510</td>\n",
       "      <td>0.215203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Modèle  n_sessions      HR@5     MRR@5\n",
       "0           Trending        4896  0.175449  0.114560\n",
       "1  Item-Item co-clic        4896  0.399510  0.215203"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Évaluation: Trending vs Item-Item co-clic\n",
    "# On compare les deux baselines sur un sous-ensemble de sessions de test.\n",
    "# Résultats: moyenne de HR@5 et MRR@5.\n",
    "\n",
    "# Évalue la baseline Trending\n",
    "eval_trending = evaluate_next_click(\n",
    "    clicks_test_p,\n",
    "    recommend_fn=recommend_trending_from_history,  # wrapper: ignore l'historique, renvoie top popularité\n",
    "    k=TOP_K,\n",
    "    max_sessions=5000,  # limite pour itérer vite\n",
    ")\n",
    "\n",
    "# Évalue la baseline co-clic\n",
    "eval_coclick = evaluate_next_click(\n",
    "    clicks_test_p,\n",
    "    recommend_fn=recommend_coclick_from_history,  # wrapper: utilise l'historique pour proposer des voisins\n",
    "    k=TOP_K,\n",
    "    max_sessions=5000,\n",
    ")\n",
    "\n",
    "# Résumé: scores moyens + nombre de sessions évaluées\n",
    "summary = pd.DataFrame([\n",
    "    {\n",
    "        \"Modèle\": \"Trending\",\n",
    "        \"n_sessions\": len(eval_trending),\n",
    "        \"HR@5\": eval_trending[\"HR@5\"].mean(),\n",
    "        \"MRR@5\": eval_trending[\"MRR@5\"].mean(),\n",
    "    },\n",
    "    {\n",
    "        \"Modèle\": \"Item-Item co-clic\",\n",
    "        \"n_sessions\": len(eval_coclick),\n",
    "        \"HR@5\": eval_coclick[\"HR@5\"].mean(),\n",
    "        \"MRR@5\": eval_coclick[\"MRR@5\"].mean(),\n",
    "    }\n",
    "])\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c531e0-4f6f-44b5-b262-922e3c8e43fa",
   "metadata": {},
   "source": [
    "## Comprendre HR@5 et MRR@5 (évaluation next-click)\n",
    "\n",
    "### HR@5 (Hit Rate @ 5)\n",
    "Pour chaque session, on “cache” le dernier clic (le vrai prochain article) et on recommande 5 articles à partir de l’historique.\n",
    "- **HR@5 = 1** si le vrai article est **dans les 5** recommandations, sinon 0.\n",
    "- La moyenne (ex: 0.3995) correspond au **% de sessions** où on a “touché juste” dans le top-5.\n",
    "\n",
    "### MRR@5 (Mean Reciprocal Rank @ 5)\n",
    "Même principe, mais on prend en compte **la position** du bon article dans le top-5 :\n",
    "- bon article en **1ère position** → score 1\n",
    "- en **2e** → 1/2 = 0.5\n",
    "- en **3e** → 1/3 ≈ 0.33\n",
    "- … absent du top-5 → 0  \n",
    "La moyenne résume “à quelle hauteur” on place le bon article quand on le trouve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0cb26-fcd5-45cd-b160-2ebe9bb8c195",
   "metadata": {},
   "source": [
    "## Interprétation des résultats obtenus\n",
    "\n",
    "| Modèle | HR@5 | MRR@5 |\n",
    "|---|---:|---:|\n",
    "| Trending | 0.175 | 0.115 |\n",
    "| Item-Item co-clic | 0.400 | 0.215 |\n",
    "\n",
    "### Lecture simple\n",
    "- **Trending (0.175)** : pour **17.5%** des sessions, le vrai prochain clic est dans les 5 recommandations.\n",
    "- **Co-clic (0.400)** : pour **40%** des sessions, le vrai prochain clic est dans les 5 recommandations.\n",
    "\n",
    "### Gain\n",
    "- Gain absolu HR@5 ≈ **+22 points** (0.400 - 0.175).\n",
    "- Le co-clic fait environ **2.3× mieux** que Trending (0.400 / 0.175 ≈ 2.28).\n",
    "\n",
    "### Conclusion MVP\n",
    "- **Trending** fournit un plancher (popularité seule).\n",
    "- **Item-Item co-clic** améliore fortement la pertinence et place plus souvent le bon article plus haut (MRR@5 plus élevé).\n",
    "- Pour une baseline transparente, ces résultats sont **très corrects** et montrent que le signal session est bien exploité.\n",
    "\n",
    "### Nuances\n",
    "- Les scores dépendent du split (fenêtre temporelle, taille train/test).\n",
    "- Ici on a évalué une version simple “dernier clic de session”; on pourra raffiner plus tard (plusieurs positions dans la session).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2057d-04a6-4123-ba7b-c4a74fe180fc",
   "metadata": {},
   "source": [
    "## Modèle 3 — Content-Based (cosine sur embeddings)\n",
    "\n",
    "Objectif : recommander des articles *similaires en contenu* à partir de ce que l’utilisateur vient de lire.\n",
    "\n",
    "Principe (MVP) :\n",
    "1. **Choisir un article “seed”** pour l’utilisateur (stratégie la plus simple : **dernier article cliqué** dans la session).\n",
    "2. Récupérer l’**embedding** de cet article (vecteur de dimension 250 fourni dans `articles_embeddings.pickle`).\n",
    "3. Calculer la **similarité cosine** entre cet embedding et ceux de tous les autres articles.\n",
    "4. Retourner les **K articles les plus similaires** (top-K), en excluant l’article seed (et éventuellement les articles déjà vus).\n",
    "\n",
    "Pourquoi c’est utile ici :\n",
    "- le dataset est **session-based** et l’intention du user dépend beaucoup du **contexte immédiat**,\n",
    "- on dispose déjà d’embeddings prêts à l’emploi (pas besoin de TF-IDF),\n",
    "- ça couvre naturellement le **cold start utilisateur** : pas besoin d’historique long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ee7ed0-7b2f-407d-886a-cd1848e3164f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (364047, 250) dtype: float32\n",
      "Metadata rows: 364047 | article_id col: article_id\n",
      "Example article_id -> eidx: [(0, 0), (1, 1), (2, 2)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Chargement embeddings + metadata + mapping article_id <-> index embedding (avec tes chemins)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "EMB_PATH = DATA_DIR / \"articles_embeddings.pickle\"\n",
    "META_PATH = DATA_DIR / \"articles_metadata.csv\"\n",
    "\n",
    "# 1) Embeddings (matrice numpy: n_articles x 250)\n",
    "with open(EMB_PATH, \"rb\") as f:\n",
    "    E = pickle.load(f)\n",
    "E = np.asarray(E, dtype=np.float32)\n",
    "\n",
    "# 2) Metadata (pour récupérer l'ordre des article_id)\n",
    "meta = pd.read_csv(META_PATH)\n",
    "\n",
    "# 3) Détection colonne ID (selon dataset, c'est souvent 'article_id')\n",
    "candidates = [\"article_id\", \"click_article_id\", \"id\", \"content_id\"]\n",
    "ARTICLE_ID_COL = next((c for c in candidates if c in meta.columns), None)\n",
    "if ARTICLE_ID_COL is None:\n",
    "    raise ValueError(f\"Impossible de trouver la colonne d'ID article dans {META_PATH}. Colonnes: {list(meta.columns)}\")\n",
    "\n",
    "article_ids = meta[ARTICLE_ID_COL].astype(int).to_numpy()\n",
    "\n",
    "# 4) Sanity check: même nombre de lignes\n",
    "if len(article_ids) != E.shape[0]:\n",
    "    raise ValueError(f\"Mismatch meta vs embeddings: meta={len(article_ids)} embeddings={E.shape[0]}\")\n",
    "\n",
    "# 5) Mappings\n",
    "article_id_to_eidx = {int(aid): i for i, aid in enumerate(article_ids)}\n",
    "eidx_to_article_id = {i: int(aid) for i, aid in enumerate(article_ids)}\n",
    "\n",
    "print(\"Embeddings shape:\", E.shape, \"dtype:\", E.dtype)\n",
    "print(\"Metadata rows:\", len(meta), \"| article_id col:\", ARTICLE_ID_COL)\n",
    "print(\"Example article_id -> eidx:\", list(article_id_to_eidx.items())[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6c69e-bd1a-41fc-a316-9d1ae0965cb4",
   "metadata": {},
   "source": [
    "### Recommandation content-based: cosine similarity (seed = dernier clic de la session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53ef3f4d-7db5-49d7-9e3f-37233673ece7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reco content-based: cosine similarity (seed = dernier clic de la session)\n",
    "import numpy as np\n",
    "\n",
    "# Normalisation une fois pour toutes (beaucoup plus rapide que normaliser à chaque requête)\n",
    "E_norm = E / (np.linalg.norm(E, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "def recommend_content_cosine_from_history(history: list[int], k: int = TOP_K) -> list[int]:\n",
    "    \"\"\"\n",
    "    Recommande top-k articles proches en contenu:\n",
    "    - seed = dernier article cliqué dans la session\n",
    "    - cosine(seed, all_items) via embeddings normalisés\n",
    "    - filtre l'article seed + items déjà vus dans la session\n",
    "    - fallback trending si history vide ou seed absent\n",
    "    \"\"\"\n",
    "    # --- (A) Pas d'historique => fallback\n",
    "    if not history:\n",
    "        return recommend_trending(k=k)\n",
    "\n",
    "    seed_id = int(history[-1])\n",
    "\n",
    "    # --- (B) Si pas d'embedding pour cet article => fallback\n",
    "    if seed_id not in article_id_to_eidx:\n",
    "        return recommend_trending(k=k)\n",
    "\n",
    "    # --- (C) Similarité cosine = produit scalaire sur embeddings normalisés\n",
    "    seed_idx = article_id_to_eidx[seed_id]\n",
    "    seed_vec = E_norm[seed_idx]  # déjà normalisé\n",
    "    sims = E_norm @ seed_vec     # (n_articles,)\n",
    "\n",
    "    # --- (D) On récupère plus que k candidats pour filtrer ensuite\n",
    "    cand = max(k * 20, k + 5)\n",
    "    top_idx = np.argpartition(-sims, cand)[:cand]\n",
    "    top_idx = top_idx[np.argsort(-sims[top_idx])]\n",
    "\n",
    "    # --- (E) Filtrage (seed + déjà vus dans la session)\n",
    "    seen = set(int(x) for x in history)\n",
    "    recs = []\n",
    "    for ei in top_idx:\n",
    "        aid = eidx_to_article_id[int(ei)]\n",
    "        if aid in seen:  # inclut seed_id\n",
    "            continue\n",
    "        recs.append(int(aid))\n",
    "        if len(recs) >= k:\n",
    "            break\n",
    "\n",
    "    # --- (F) Complète avec trending si besoin\n",
    "    if len(recs) < k:\n",
    "        for aid in trending_list:\n",
    "            if aid not in seen and aid not in recs:\n",
    "                recs.append(int(aid))\n",
    "            if len(recs) >= k:\n",
    "                break\n",
    "\n",
    "    return recs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4606c34-1f84-4830-8f3d-8afcde00a3e0",
   "metadata": {},
   "source": [
    "### Évaluation du modèle Content-based (cosine embeddings) sur le même protocole next-click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28445c27-a3a2-41cb-b2e6-2ba9cd403ca2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>MRR@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trending</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.175449</td>\n",
       "      <td>0.114560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item-Item co-clic</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.399510</td>\n",
       "      <td>0.215203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Content cosine (seed=dernier clic)</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.005375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Content cosine (seed=dernier clic)</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.005375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Modèle  n_sessions      HR@5     MRR@5\n",
       "0                            Trending        4896  0.175449  0.114560\n",
       "1                   Item-Item co-clic        4896  0.399510  0.215203\n",
       "2  Content cosine (seed=dernier clic)        4896  0.010621  0.005375\n",
       "3  Content cosine (seed=dernier clic)        4896  0.010621  0.005375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Évaluation du modèle Content-based (cosine embeddings) sur le même protocole next-click\n",
    "eval_content = evaluate_next_click(\n",
    "    clicks_test_p,\n",
    "    recommend_fn=recommend_content_cosine_from_history,\n",
    "    k=TOP_K,\n",
    "    max_sessions=5000,\n",
    ")\n",
    "\n",
    "# Ajout au tableau récapitulatif\n",
    "summary = pd.concat(\n",
    "    [\n",
    "        summary,\n",
    "        pd.DataFrame([\n",
    "            {\n",
    "                \"Modèle\": \"Content cosine (seed=dernier clic)\",\n",
    "                \"n_sessions\": len(eval_content),\n",
    "                \"HR@5\": eval_content[\"HR@5\"].mean(),\n",
    "                \"MRR@5\": eval_content[\"MRR@5\"].mean(),\n",
    "             }\n",
    "        ]),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde7681-13f1-49e9-afd9-0e3a9267973c",
   "metadata": {},
   "source": [
    "## Comparer un modèle aux baselines\n",
    "\n",
    "On testera un modèle “plus avancé”, on le comparera aux baselines.\n",
    "\n",
    "### Baseline popularité (Trending)\n",
    "- C’est le **plancher** incontournable.\n",
    "- Si le modèle ne fait pas mieux que Trending, il ne vaut pas le coût (complexité / déploiement).\n",
    "\n",
    "### Baseline co-clic (Item-Item)\n",
    "- Baseline “simple mais forte” en recommandation session-based.\n",
    "- Si le modèle ne dépasse pas co-clic, il est difficile de le justifier.\n",
    "\n",
    "### Important pour ce projet\n",
    "- Le dataset est **implicite + orienté sessions** (next-click), on a pas de rating.\n",
    "- Donc l’évaluation restera centrée sur des métriques top-K comme **HR@5** et **MRR@5**,\n",
    "  sur le même split (temporel ou par sessions) pour comparer équitablement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96589d-30db-401f-a25d-8f21be8ce994",
   "metadata": {},
   "source": [
    "## Pourquoi Surprise peut être “hors-sujet méthodologie” pour ce dataset\n",
    "\n",
    "### 1) Surprise est pensé pour des **notes explicites**\n",
    "Les algorithmes de Surprise (SVD, KNN, etc.) cherchent à prédire une **valeur de rating** (ex : 1 à 5).  \n",
    "Ici, on n’a pas de notes : on a des **clics** (feedback implicite) et des **sessions**.\n",
    "\n",
    "-> Pour utiliser Surprise, il faut **inventer** une “note” artificielle (ex : clic = 1).  \n",
    "Le problème : on ne sait pas quoi faire des **non-clics** (0 ? absent ?) et ces choix peuvent fortement biaiser le modèle.\n",
    "\n",
    "### 2) Le dataset est **session-based / next-click**\n",
    "L’objectif naturel ici est de prédire le **prochain clic** dans une session (séquence A → B → C).  \n",
    "Surprise modélise plutôt une préférence globale user–item et ne capture pas directement la **séquence** et la **récence**.\n",
    "\n",
    "### 3) Conséquence : perte de temps et risque de résultats moins pertinents\n",
    "On passe du temps à :\n",
    "- définir une pseudo-note,\n",
    "- justifier la transformation,\n",
    "- tout en n’exploitant pas le signal principal du dataset (sessions / next-click).\n",
    "\n",
    "C’est pour cela que Surprise peut être considéré “hors-sujet” méthodologiquement ici, même s’il est facile à installer dans un cadre MVP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bad85a-ed5f-42ce-9467-56d6272d627e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446659ec-a191-40de-8e90-53e28ef957b7",
   "metadata": {},
   "source": [
    "## Mise en place et évaluation d'un modèle basé sur LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d2bf84-fad4-41e3-bc13-d3a1c500e398",
   "metadata": {},
   "source": [
    "### Préparation (imports + chargement des embeddings)\n",
    "\n",
    "Objectifs :\n",
    "- importer LightFM (modèle hybride implicite),\n",
    "- charger les embeddings d’articles déjà fournis (250 dimensions),\n",
    "- inspecter la structure du pickle (selon la source, ce peut être une matrice ou un dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1460445b-8de5-4d7a-b861-ef891dad410d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myContent/lib/python3.10/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type embeddings pickle: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports nécessaires au modèle (LightFM) et aux matrices creuses (sparse)\n",
    "from lightfm import LightFM\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "\n",
    "# Chargement des embeddings (pickle)\n",
    "# Selon le dataset, ce pickle peut contenir:\n",
    "# - soit une matrice numpy (N_articles x 250)\n",
    "# - soit un dict contenant une matrice + une liste d'ids\n",
    "with open(EMBEDDINGS_PATH, \"rb\") as f:\n",
    "    emb_obj = pickle.load(f)\n",
    "\n",
    "print(\"Type embeddings pickle:\", type(emb_obj))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba9ff8-ef94-4676-9646-2ac30c295af9",
   "metadata": {},
   "source": [
    "## Construire une table `article_id -> embedding`\n",
    "\n",
    "Objectifs :\n",
    "- construire un DataFrame `emb_df` indexé par `article_id`,\n",
    "- avoir les colonnes d’embeddings `e0..e249`,\n",
    "- aligner correctement les lignes d'embeddings avec les ids d’articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c23f2d92-9201-44ed-9264-2915e7609c36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles_metadata shape: (364047, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513144419000</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405341936000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1408667706000</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  created_at_ts  publisher_id  words_count\n",
       "0           0            0  1513144419000             0          168\n",
       "1           1            1  1405341936000             0          189\n",
       "2           2            1  1408667706000             0          250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes candidates pour article_id: ['article_id']\n",
      "ARTICLE_ID_COL retenue = article_id\n",
      "emb_df shape: (364047, 251)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e0</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>e4</th>\n",
       "      <th>e5</th>\n",
       "      <th>e6</th>\n",
       "      <th>e7</th>\n",
       "      <th>e8</th>\n",
       "      <th>e9</th>\n",
       "      <th>...</th>\n",
       "      <th>e241</th>\n",
       "      <th>e242</th>\n",
       "      <th>e243</th>\n",
       "      <th>e244</th>\n",
       "      <th>e245</th>\n",
       "      <th>e246</th>\n",
       "      <th>e247</th>\n",
       "      <th>e248</th>\n",
       "      <th>e249</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.161183</td>\n",
       "      <td>-0.957233</td>\n",
       "      <td>-0.137944</td>\n",
       "      <td>0.050855</td>\n",
       "      <td>0.830055</td>\n",
       "      <td>0.901365</td>\n",
       "      <td>-0.335148</td>\n",
       "      <td>-0.559561</td>\n",
       "      <td>-0.500603</td>\n",
       "      <td>0.165183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313999</td>\n",
       "      <td>0.636412</td>\n",
       "      <td>0.169179</td>\n",
       "      <td>0.540524</td>\n",
       "      <td>-0.813182</td>\n",
       "      <td>0.286870</td>\n",
       "      <td>-0.231686</td>\n",
       "      <td>0.597416</td>\n",
       "      <td>0.409623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.523216</td>\n",
       "      <td>-0.974058</td>\n",
       "      <td>0.738608</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>0.626294</td>\n",
       "      <td>0.485297</td>\n",
       "      <td>-0.715657</td>\n",
       "      <td>-0.897996</td>\n",
       "      <td>-0.359747</td>\n",
       "      <td>0.398246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823124</td>\n",
       "      <td>0.412688</td>\n",
       "      <td>-0.338654</td>\n",
       "      <td>0.320787</td>\n",
       "      <td>0.588643</td>\n",
       "      <td>-0.594137</td>\n",
       "      <td>0.182828</td>\n",
       "      <td>0.397090</td>\n",
       "      <td>-0.834364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.619619</td>\n",
       "      <td>-0.972960</td>\n",
       "      <td>-0.207360</td>\n",
       "      <td>-0.128861</td>\n",
       "      <td>0.044748</td>\n",
       "      <td>-0.387535</td>\n",
       "      <td>-0.730477</td>\n",
       "      <td>-0.066126</td>\n",
       "      <td>-0.754899</td>\n",
       "      <td>-0.242004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473184</td>\n",
       "      <td>0.377866</td>\n",
       "      <td>-0.863887</td>\n",
       "      <td>-0.383365</td>\n",
       "      <td>0.137721</td>\n",
       "      <td>-0.810877</td>\n",
       "      <td>-0.447580</td>\n",
       "      <td>0.805932</td>\n",
       "      <td>-0.285284</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         e0        e1        e2        e3        e4        e5        e6  \\\n",
       "0 -0.161183 -0.957233 -0.137944  0.050855  0.830055  0.901365 -0.335148   \n",
       "1 -0.523216 -0.974058  0.738608  0.155234  0.626294  0.485297 -0.715657   \n",
       "2 -0.619619 -0.972960 -0.207360 -0.128861  0.044748 -0.387535 -0.730477   \n",
       "\n",
       "         e7        e8        e9  ...      e241      e242      e243      e244  \\\n",
       "0 -0.559561 -0.500603  0.165183  ...  0.313999  0.636412  0.169179  0.540524   \n",
       "1 -0.897996 -0.359747  0.398246  ...  0.823124  0.412688 -0.338654  0.320787   \n",
       "2 -0.066126 -0.754899 -0.242004  ...  0.473184  0.377866 -0.863887 -0.383365   \n",
       "\n",
       "       e245      e246      e247      e248      e249  article_id  \n",
       "0 -0.813182  0.286870 -0.231686  0.597416  0.409623           0  \n",
       "1  0.588643 -0.594137  0.182828  0.397090 -0.834364           1  \n",
       "2  0.137721 -0.810877 -0.447580  0.805932 -0.285284           2  \n",
       "\n",
       "[3 rows x 251 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Chargement des métadonnées articles: permet d'identifier la colonne \"article_id\"\n",
    "articles_meta = pd.read_csv(ARTICLES_META_PATH)\n",
    "\n",
    "print(\"articles_metadata shape:\", articles_meta.shape)\n",
    "display(articles_meta.head(3))\n",
    "\n",
    "# Détection (simple) de la colonne id article\n",
    "possible_id_cols = [c for c in articles_meta.columns if \"article\" in c and \"id\" in c]\n",
    "print(\"Colonnes candidates pour article_id:\", possible_id_cols)\n",
    "\n",
    "# Choix de la colonne article_id (ajuste si nécessaire)\n",
    "ARTICLE_ID_COL = \"article_id\" if \"article_id\" in articles_meta.columns else possible_id_cols[0]\n",
    "print(\"ARTICLE_ID_COL retenue =\", ARTICLE_ID_COL)\n",
    "\n",
    "\n",
    "# Fonction: construire un DataFrame embeddings\n",
    "# - Si le pickle est un dict: on récupère ids + matrice\n",
    "# - Si le pickle est une matrice: on suppose qu'elle est dans le même ordre que articles_metadata\n",
    "def build_embeddings_df(emb_obj, articles_meta: pd.DataFrame, article_id_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construit un DataFrame avec une ligne par article:\n",
    "    - colonne article_id\n",
    "    - colonnes e0..e(D-1) pour les embeddings\n",
    "    \"\"\"\n",
    "    # Cas 1: pickle = dict\n",
    "    if isinstance(emb_obj, dict):\n",
    "        # Cherche une clé d'ids\n",
    "        ids = None\n",
    "        for key_ids in [\"article_id\", \"article_ids\", \"ids\"]:\n",
    "            if key_ids in emb_obj:\n",
    "                ids = np.array(emb_obj[key_ids]).astype(int)\n",
    "                break\n",
    "\n",
    "        # Cherche une clé de matrice embeddings\n",
    "        mat = None\n",
    "        for key_mat in [\"embeddings\", \"matrix\", \"X\"]:\n",
    "            if key_mat in emb_obj:\n",
    "                mat = np.array(emb_obj[key_mat])\n",
    "                break\n",
    "\n",
    "        if ids is None or mat is None:\n",
    "            raise ValueError(\"Pickle dict non reconnu: attend des clés ids + matrice embeddings\")\n",
    "\n",
    "        df = pd.DataFrame(mat, columns=[f\"e{i}\" for i in range(mat.shape[1])])\n",
    "        df[article_id_col] = ids\n",
    "        return df\n",
    "\n",
    "    # Cas 2: pickle = matrice numpy\n",
    "    mat = np.array(emb_obj)\n",
    "    if mat.ndim != 2:\n",
    "        raise ValueError(\"Pickle embeddings non reconnu: attendu matrice 2D ou dict\")\n",
    "\n",
    "    # Hypothèse simple (fréquente sur ce dataset): embeddings alignés sur articles_metadata\n",
    "    ids = articles_meta[article_id_col].astype(int).to_numpy()\n",
    "\n",
    "    if len(ids) != mat.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"Mismatch: metadata a {len(ids)} ids mais embeddings a {mat.shape[0]} lignes. \"\n",
    "            \"Il faut retrouver l'ordre exact / la liste d'ids.\"\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(mat, columns=[f\"e{i}\" for i in range(mat.shape[1])])\n",
    "    df[article_id_col] = ids\n",
    "    return df\n",
    "\n",
    "\n",
    "# Construction du DataFrame embeddings\n",
    "emb_df = build_embeddings_df(emb_obj, articles_meta, ARTICLE_ID_COL)\n",
    "print(\"emb_df shape:\", emb_df.shape)\n",
    "display(emb_df.head(3))\n",
    "\n",
    "# On indexe par article_id pour accès rapide\n",
    "# On enlève d'éventuels doublons d'ids\n",
    "emb_df = emb_df.drop_duplicates(subset=[ARTICLE_ID_COL]).set_index(ARTICLE_ID_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1211742-ff0f-4954-9e5c-dc47c031793f",
   "metadata": {},
   "source": [
    "## Construire les mappings et les matrices (interactions + item_features) pour LightFM\n",
    "\n",
    "Objectifs :\n",
    "- créer un index dense pour les utilisateurs et articles (LightFM travaille sur 0..n-1),\n",
    "- construire la matrice `interactions` à partir des clics (implicite),\n",
    "- construire la matrice `item_features` à partir des embeddings (250D),\n",
    "- restreindre aux articles présents dans les embeddings (sinon pas de features).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4505b0b-22a7-49a8-b57d-2c0786af3ea8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train clicks after embedding filter: (118339, 3)\n",
      "n_users: 39218 | n_items: 4097\n",
      "interactions shape: (39218, 4097) | nnz: 117633\n",
      "item_features shape: (4097, 250)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Bloc 1: préparation d'un train user/article minimal pour LightFM\n",
    "# On prend uniquement (user_id, article_id) et on filtre les articles sans embeddings.\n",
    "train_df = clicks_train_p[[COL_USER, COL_ITEM, \"ts\"]].copy()\n",
    "train_df = train_df.rename(columns={COL_USER: \"user_id\", COL_ITEM: \"article_id\"})\n",
    "\n",
    "train_df[\"user_id\"] = train_df[\"user_id\"].astype(int)\n",
    "train_df[\"article_id\"] = train_df[\"article_id\"].astype(int)\n",
    "\n",
    "# Filtrage: on garde uniquement les articles qui ont un embedding\n",
    "train_df = train_df[train_df[\"article_id\"].isin(emb_df.index)]\n",
    "print(\"Train clicks after embedding filter:\", train_df.shape)\n",
    "\n",
    "# --- Bloc 2: création des mappings (id réel -> index)\n",
    "# LightFM attend des indices 0..n-1.\n",
    "user_ids = np.sort(train_df[\"user_id\"].unique())\n",
    "item_ids = np.sort(train_df[\"article_id\"].unique())\n",
    "\n",
    "user_to_idx = {uid: i for i, uid in enumerate(user_ids)}\n",
    "item_to_idx = {aid: i for i, aid in enumerate(item_ids)}\n",
    "idx_to_item = {i: aid for aid, i in item_to_idx.items()}\n",
    "\n",
    "n_users = len(user_to_idx)\n",
    "n_items = len(item_to_idx)\n",
    "print(\"n_users:\", n_users, \"| n_items:\", n_items)\n",
    "\n",
    "# --- Bloc 3: construction de la matrice interactions (implicite)\n",
    "# Ici: interaction = 1 si (user,item) a été cliqué dans le train.\n",
    "ui = train_df.drop_duplicates(subset=[\"user_id\", \"article_id\"])\n",
    "\n",
    "u = ui[\"user_id\"].map(user_to_idx).to_numpy()\n",
    "i = ui[\"article_id\"].map(item_to_idx).to_numpy()\n",
    "data = np.ones(len(ui), dtype=np.float32)\n",
    "\n",
    "interactions = csr_matrix((data, (u, i)), shape=(n_users, n_items))\n",
    "print(\"interactions shape:\", interactions.shape, \"| nnz:\", interactions.nnz)\n",
    "\n",
    "# --- Bloc 4: construction de la matrice item_features (embeddings)\n",
    "# On construit une matrice (n_items x 250) alignée sur item_to_idx.\n",
    "emb_cols = [c for c in emb_df.columns if c.startswith(\"e\")]\n",
    "\n",
    "item_emb_matrix = np.zeros((n_items, len(emb_cols)), dtype=np.float32)\n",
    "for aid, idx in item_to_idx.items():\n",
    "    item_emb_matrix[idx] = emb_df.loc[aid, emb_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "# Conversion en sparse (LightFM accepte sparse)\n",
    "item_features = csr_matrix(item_emb_matrix)\n",
    "print(\"item_features shape:\", item_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93704760-1504-498c-af99-9eef9d444452",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users seen(train): 39218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construire \"seen\" sur le train (items vus par user) pour filtrer pendant l'inférence\n",
    "import pandas as pd\n",
    "\n",
    "COL_USER = \"user_id\"\n",
    "COL_ITEM = \"click_article_id\"\n",
    "\n",
    "# Suppose que tu as clicks_train_p, sinon adapte (ou supprime et utilise ton dict déjà existant)\n",
    "# clicks_train_p doit contenir au moins user_id, article_id\n",
    "user_seen_train = (\n",
    "    clicks_train_p.groupby(COL_USER)[COL_ITEM]\n",
    "    .apply(lambda s: set(s.astype(int).tolist()))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "print(\"n_users seen(train):\", len(user_seen_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f53328-ee5a-43f2-8403-e0807f81849d",
   "metadata": {},
   "source": [
    "## Entraînement (WARP) + évaluation MVP (par utilisateur)\n",
    "\n",
    "Objectifs :\n",
    "- entraîner un modèle LightFM en implicite avec embeddings (hybride),\n",
    "- évaluer avec un protocole MVP simple:\n",
    "  - pour chaque user, on prend son **premier clic en test** comme \"cible\",\n",
    "  - on recommande top-5 à partir de son historique train,\n",
    "  - on calcule HR@5 et MRR@5,\n",
    "  - fallback Trending si user inconnu (cold start).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb944ab4-a9d2-4170-a182-44c006341bd0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisateur avec au moins 1 click dans le test: 4819\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>Protocole d’évaluation</th>\n",
       "      <th>Commentaire court</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trending</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.175449</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item-Item co-clic</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.399510</td>\n",
       "      <td>0.215203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Content cosine (seed=dernier clic)</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Content cosine (seed=dernier clic)</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightFM</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.102407</td>\n",
       "      <td>Next-click par session</td>\n",
       "      <td>Moins adapté à la séquence</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightFM</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.413364</td>\n",
       "      <td>0.271256</td>\n",
       "      <td>Par user (premier clic test)</td>\n",
       "      <td>Préférence globale utilisateur</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1164</td>\n",
       "      <td>0.081615</td>\n",
       "      <td>0.042354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LightFM (users connus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightFM (hybride embeddings)</td>\n",
       "      <td>4819</td>\n",
       "      <td>0.413364</td>\n",
       "      <td>0.271256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Modèle  n_sessions      HR@5     MRR@5  \\\n",
       "0                            Trending        4896  0.175449  0.114560   \n",
       "1                   Item-Item co-clic        4896  0.399510  0.215203   \n",
       "2  Content cosine (seed=dernier clic)        4896  0.010621  0.005375   \n",
       "3  Content cosine (seed=dernier clic)        4896  0.010621  0.005375   \n",
       "4                             LightFM        4896  0.161765  0.102407   \n",
       "5                             LightFM        4896  0.413364  0.271256   \n",
       "6                                 NaN        1164  0.081615  0.042354   \n",
       "7        LightFM (hybride embeddings)        4819  0.413364  0.271256   \n",
       "\n",
       "         Protocole d’évaluation               Commentaire court  \\\n",
       "0                           NaN                             NaN   \n",
       "1                           NaN                             NaN   \n",
       "2                           NaN                             NaN   \n",
       "3                           NaN                             NaN   \n",
       "4        Next-click par session      Moins adapté à la séquence   \n",
       "5  Par user (premier clic test)  Préférence globale utilisateur   \n",
       "6                           NaN                             NaN   \n",
       "7                           NaN                             NaN   \n",
       "\n",
       "                    model  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "5                     NaN  \n",
       "6  LightFM (users connus)  \n",
       "7                     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# --- Bloc 1: entraînement LightFM\n",
    "# WARP est adapté au ranking implicite (apprendre à mettre les bons items en haut).\n",
    "model = LightFM(loss=\"warp\", no_components=32, learning_rate=0.05, random_state=SEED)\n",
    "model.fit(interactions, item_features=item_features, epochs=10, num_threads=4)\n",
    "\n",
    "# --- Bloc 2: préparation du test \"par user\"\n",
    "# On prend le premier clic en test de chaque user comme \"vrai prochain item\".\n",
    "test_df = clicks_test_p[[COL_USER, COL_ITEM, \"ts\"]].copy()\n",
    "test_df = test_df.rename(columns={COL_USER: \"user_id\", COL_ITEM: \"article_id\"})\n",
    "\n",
    "test_df[\"user_id\"] = test_df[\"user_id\"].astype(int)\n",
    "test_df[\"article_id\"] = test_df[\"article_id\"].astype(int)\n",
    "test_df = test_df.sort_values([\"user_id\", \"ts\"], ascending=[True, True])\n",
    "\n",
    "first_test_click = test_df.groupby(\"user_id\", as_index=False).first()[[\"user_id\", \"article_id\"]]\n",
    "print(\"Utilisateur avec au moins 1 click dans le test:\", first_test_click.shape[0])\n",
    "\n",
    "# --- Fonction métriques: HR@k et MRR@k\n",
    "# HR@k: 1 si le vrai item est dans le top-k, sinon 0\n",
    "# MRR@k: 1/rang si présent, sinon 0\n",
    "def hr_mrr_at_k(true_item: int, recs: list[int], k: int = TOP_K) -> tuple[float, float]:\n",
    "    topk = recs[:k]\n",
    "    if true_item in topk:\n",
    "        rank = topk.index(true_item) + 1\n",
    "        return 1.0, 1.0 / rank\n",
    "    return 0.0, 0.0\n",
    "\n",
    "# --- Pré-calcul: tous les indices items, utile pour scorer rapidement\n",
    "all_item_idx = np.arange(n_items, dtype=np.int32)\n",
    "\n",
    "# --- Pré-calcul: historique train par user pour filtrer les items déjà vus\n",
    "user_seen = (\n",
    "    train_df.drop_duplicates(subset=[\"user_id\", \"article_id\"])\n",
    "    .groupby(\"user_id\")[\"article_id\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# --- Fonction recommandation LightFM\n",
    "# - si user inconnu -> fallback trending\n",
    "# - sinon, on score tous les items et on prend les meilleurs\n",
    "# - on filtre les items déjà vus\n",
    "# - on complète avec trending si nécessaire\n",
    "def recommend_lightfm(user_id: int, k: int = TOP_K) -> list[int]:\n",
    "    \"\"\"\n",
    "    Recommande top-k articles pour un user:\n",
    "    - scores LightFM (hybride embeddings)\n",
    "    - filtrage des items déjà vus\n",
    "    - fallback trending si besoin\n",
    "    \"\"\"\n",
    "    if user_id not in user_to_idx:\n",
    "        return recommend_trending(k=k)\n",
    "\n",
    "    uidx = user_to_idx[user_id]\n",
    "    scores = model.predict(uidx, all_item_idx, item_features=item_features)\n",
    "\n",
    "    # On prend plus que k pour pouvoir filtrer les \"seen\"\n",
    "    candidate_n = k * 20\n",
    "    top_idx = np.argpartition(-scores, candidate_n)[:candidate_n]\n",
    "    top_idx = top_idx[np.argsort(-scores[top_idx])]\n",
    "\n",
    "    seen = set(user_seen.get(user_id, []))\n",
    "    recs = []\n",
    "    for ii in top_idx:\n",
    "        aid = idx_to_item[int(ii)]\n",
    "        if aid in seen:\n",
    "            continue\n",
    "        recs.append(aid)\n",
    "        if len(recs) >= k:\n",
    "            break\n",
    "\n",
    "    # Complète si on n'a pas assez de recos\n",
    "    if len(recs) < k:\n",
    "        for aid in TRENDING_LIST:\n",
    "            if aid not in seen and aid not in recs:\n",
    "                recs.append(aid)\n",
    "            if len(recs) >= k:\n",
    "                break\n",
    "\n",
    "    return recs\n",
    "\n",
    "# --- Bloc 3: boucle d'évaluation\n",
    "# On compare les recommandations au vrai item test de chaque user.\n",
    "rows = []\n",
    "for _, r in first_test_click.iterrows():\n",
    "    uid = int(r[\"user_id\"])\n",
    "    true_item = int(r[\"article_id\"])\n",
    "\n",
    "    recs = recommend_lightfm(uid, k=TOP_K)\n",
    "    hr, mrr = hr_mrr_at_k(true_item, recs, k=TOP_K)\n",
    "    rows.append({\"user_id\": uid, \"true_item\": true_item, \"HR@5\": hr, \"MRR@5\": mrr})\n",
    "\n",
    "eval_lightfm = pd.DataFrame(rows)\n",
    "\n",
    "# --- Bloc 4: résumé des scores\n",
    "summary = pd.concat(\n",
    "    [\n",
    "        summary,\n",
    "        pd.DataFrame([\n",
    "            {\n",
    "                \"Modèle\": \"LightFM (hybride embeddings)\",\n",
    "                \"n_sessions\": len(eval_lightfm),\n",
    "                \"HR@5\": eval_lightfm[\"HR@5\"].mean(),\n",
    "                \"MRR@5\": eval_lightfm[\"MRR@5\"].mean(),\n",
    "             }\n",
    "        ]),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384e88a-7aa0-4b3f-b994-6f0734eb76d6",
   "metadata": {},
   "source": [
    "## Résultats (synthèse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "feb7542e-75eb-41f7-a719-e81f08ef9c40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>Protocole d’évaluation</th>\n",
       "      <th>Commentaire court</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trending</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.175449</td>\n",
       "      <td>0.114560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item-Item co-clic</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.399510</td>\n",
       "      <td>0.215203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Content cosine (seed=dernier clic)</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Content cosine (seed=dernier clic)</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightFM</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.102407</td>\n",
       "      <td>Next-click par session</td>\n",
       "      <td>Moins adapté à la séquence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightFM</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.413364</td>\n",
       "      <td>0.271256</td>\n",
       "      <td>Par user (premier clic test)</td>\n",
       "      <td>Préférence globale utilisateur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Modèle  n_sessions      HR@5     MRR@5  \\\n",
       "0                            Trending        4896  0.175449  0.114560   \n",
       "1                   Item-Item co-clic        4896  0.399510  0.215203   \n",
       "2  Content cosine (seed=dernier clic)        4896  0.010621  0.005375   \n",
       "3  Content cosine (seed=dernier clic)        4896  0.010621  0.005375   \n",
       "4                             LightFM        4896  0.161765  0.102407   \n",
       "5                             LightFM        4896  0.413364  0.271256   \n",
       "\n",
       "         Protocole d’évaluation               Commentaire court  \n",
       "0                           NaN                             NaN  \n",
       "1                           NaN                             NaN  \n",
       "2                           NaN                             NaN  \n",
       "3                           NaN                             NaN  \n",
       "4        Next-click par session      Moins adapté à la séquence  \n",
       "5  Par user (premier clic test)  Préférence globale utilisateur  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Ajout au tableau récapitulatif\n",
    "# LightFM évalué avec le même protocole que les baselines\n",
    "summary = pd.concat(\n",
    "    [\n",
    "        summary,\n",
    "        pd.DataFrame([\n",
    "            {\n",
    "                \"Modèle\": \"LightFM\",\n",
    "                \"n_sessions\": len(eval_content),\n",
    "                \"Protocole d’évaluation\": \"Next-click par session\",\n",
    "                \"HR@5\": eval_lightfm[f\"HR@{TOP_K}\"].mean(),\n",
    "                \"MRR@5\": eval_lightfm[f\"MRR@{TOP_K}\"].mean(),\n",
    "                \"Commentaire court\": \"Moins adapté à la séquence\",\n",
    "            }\n",
    "        ]),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# LightFM évalué par user (si disponible)\n",
    "if \"summary_lightfm\" in globals():\n",
    "    summary = pd.concat(\n",
    "        [        \n",
    "            summary,   \n",
    "            pd.DataFrame([\n",
    "                {\n",
    "                    \"Modèle\": \"LightFM\",\n",
    "                    \"n_sessions\": len(eval_content),\n",
    "                    \"Protocole d’évaluation\": \"Par user (premier clic test)\",\n",
    "                    \"HR@5\": float(summary_lightfm[\"HR@5\"].iloc[0]),\n",
    "                    \"MRR@5\": float(summary_lightfm[\"MRR@5\"].iloc[0]),\n",
    "                    \"Commentaire court\": \"Préférence globale utilisateur\",\n",
    "                }\n",
    "            ]),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    \n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cba4bb-dec4-4421-b8e5-8bd89c6e70d9",
   "metadata": {},
   "source": [
    "\n",
    "**Comparaison rapide**\n",
    "- **Co‑clic** domine souvent sur le **next‑click** car il exploite la co‑occurrence en session.\n",
    "- **LightFM** capte la préférence utilisateur globale, donc il peut être moins performant sur un next‑click strict.\n",
    "- **Trending** reste le plancher à battre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5a375-0133-4ae0-b3cb-fce8add91b4f",
   "metadata": {},
   "source": [
    "## Types d’évaluation et pourquoi\n",
    "\n",
    "1. **Next‑click par session**\n",
    "   - On cache le dernier clic d’une session et on essaie de le prédire.\n",
    "   - **Pourquoi** : mesure la qualité “immédiate” des recos en contexte de session (usage typique d’un fil de lecture).\n",
    "\n",
    "2. **Par user (premier clic test)**\n",
    "   - Pour chaque user, on prend le premier clic dans la période test.\n",
    "   - **Pourquoi** : évalue la capacité du modèle à capter une préférence utilisateur globale, indépendante de la séquence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce66fe5-bb06-4c5f-b53a-b260327a5ffd",
   "metadata": {},
   "source": [
    "## Exemple de recommandations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d43208a5-8650-4e5e-9e68-fac4e5db9daa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommended_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[162369, 161178, 156355, 158888, 156718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[207122, 119592, 119591, 234449, 108843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[32486, 96663, 304169, 236336, 303842]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[237687, 284846, 160154, 114428, 156025]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[163010, 65376, 59758, 49123, 284844]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                      recommended_articles\n",
       "0        0  [162369, 161178, 156355, 158888, 156718]\n",
       "1        1  [207122, 119592, 119591, 234449, 108843]\n",
       "2        2    [32486, 96663, 304169, 236336, 303842]\n",
       "3        3  [237687, 284846, 160154, 114428, 156025]\n",
       "4        4     [163010, 65376, 59758, 49123, 284844]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb users: 39218\n",
      "Exemple recos: [162369, 161178, 156355, 158888, 156718]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Bloc 1: fonction de génération top-k pour un user index (LightFM)\n",
    "# On réutilise model, item_features, all_item_idx, idx_to_item, user_seen, TRENDING_LIST.\n",
    "\n",
    "def topk_for_user(uid: int, k: int = TOP_K, candidate_mult: int = 50) -> list[int]:\n",
    "    \"\"\"\n",
    "    Génère top-k recommandations LightFM pour un user connu (uid réel).\n",
    "    - candidate_mult: on prend k*candidate_mult candidats pour compenser le filtrage \"seen\".\n",
    "    \"\"\"\n",
    "    if uid not in user_to_idx:\n",
    "        return recommend_trending(k=k)\n",
    "\n",
    "    uidx = user_to_idx[uid]\n",
    "    scores = model.predict(uidx, all_item_idx, item_features=item_features)\n",
    "\n",
    "    candidate_n = min(len(scores), k * candidate_mult)\n",
    "    top_idx = np.argpartition(-scores, candidate_n)[:candidate_n]\n",
    "    top_idx = top_idx[np.argsort(-scores[top_idx])]\n",
    "\n",
    "    seen = set(user_seen.get(uid, []))\n",
    "    recs = []\n",
    "\n",
    "    for ii in top_idx:\n",
    "        aid = idx_to_item[int(ii)]\n",
    "        if aid in seen:\n",
    "            continue\n",
    "        recs.append(aid)\n",
    "        if len(recs) >= k:\n",
    "            break\n",
    "\n",
    "    # Complète avec trending si besoin\n",
    "    if len(recs) < k:\n",
    "        for aid in TRENDING_LIST:\n",
    "            if aid not in seen and aid not in recs:\n",
    "                recs.append(aid)\n",
    "            if len(recs) >= k:\n",
    "                break\n",
    "\n",
    "    return recs\n",
    "\n",
    "\n",
    "# --- Bloc 2: calcul des top-5 pour tous les users du modèle\n",
    "rows = []\n",
    "for uid in user_to_idx.keys():\n",
    "    rows.append({\"user_id\": int(uid), \"recommended_articles\": topk_for_user(int(uid), k=TOP_K)})\n",
    "\n",
    "user_top5 = pd.DataFrame(rows)\n",
    "display(user_top5.head())\n",
    "\n",
    "print(\"Nb users:\", len(user_top5))\n",
    "print(\"Exemple recos:\", user_top5.iloc[0][\"recommended_articles\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294bf58a-ef4d-478c-806d-d87998249f49",
   "metadata": {},
   "source": [
    "## Evaluations des recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753796f-0467-49c0-bb96-348d988da6a0",
   "metadata": {},
   "source": [
    "### Cohérence de contenu et cohérence avec une session d’une recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c99e363-58e7-434e-a1cb-5bdd23cf1012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessions checked: 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internal_cosine</th>\n",
       "      <th>seed_cosine</th>\n",
       "      <th>emb_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.347566</td>\n",
       "      <td>0.336516</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.067914</td>\n",
       "      <td>0.131163</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.248574</td>\n",
       "      <td>-0.166835</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.254442</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.294084</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.455563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.831407</td>\n",
       "      <td>0.713100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       internal_cosine  seed_cosine  emb_coverage\n",
       "count       300.000000   300.000000         300.0\n",
       "mean          0.347566     0.336516           1.0\n",
       "std           0.067914     0.131163           0.0\n",
       "min           0.248574    -0.166835           1.0\n",
       "25%           0.324444     0.254442           1.0\n",
       "50%           0.324444     0.294084           1.0\n",
       "75%           0.324444     0.455563           1.0\n",
       "max           0.831407     0.713100           1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _vec(article_id: int):\n",
    "    \"\"\"Retourne le vecteur embedding normalisé d'un article, ou None si absent.\"\"\"\n",
    "    article_id = int(article_id)\n",
    "    if article_id not in article_id_to_eidx:\n",
    "        return None\n",
    "    return E_norm[article_id_to_eidx[article_id]]\n",
    "\n",
    "def coherence_internal(recs: list[int]) -> float:\n",
    "    \"\"\"Cohérence interne: moyenne des cosines entre toutes les paires de recs.\"\"\"\n",
    "    vecs = [_vec(a) for a in recs]\n",
    "    vecs = [v for v in vecs if v is not None]\n",
    "    if len(vecs) < 2:\n",
    "        return np.nan\n",
    "    V = np.vstack(vecs)          # (m, d)\n",
    "    S = V @ V.T                  # cosine matrix (m, m)\n",
    "    m = S.shape[0]\n",
    "    vals = [S[i, j] for i in range(m) for j in range(i+1, m)]\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "def coherence_to_seed(seed_id: int, recs: list[int]) -> float:\n",
    "    \"\"\"Cohérence au seed: moyenne cosine(seed, rec_i).\"\"\"\n",
    "    seed_v = _vec(seed_id)\n",
    "    if seed_v is None:\n",
    "        return np.nan\n",
    "    sims = []\n",
    "    for a in recs:\n",
    "        v = _vec(a)\n",
    "        if v is None:\n",
    "            continue\n",
    "        sims.append(float(v @ seed_v))\n",
    "    return float(np.mean(sims)) if sims else np.nan\n",
    "\n",
    "# --- Audit: LightFM (tu peux remplacer recommend_lightfm par une autre stratégie)\n",
    "rows = []\n",
    "MAX_SESSIONS = 300\n",
    "checked = 0\n",
    "\n",
    "for sid, g in clicks_test_p.groupby(\"session_id\"):\n",
    "    if len(g) < 2:\n",
    "        continue\n",
    "    g = g.sort_values(\"click_timestamp\")\n",
    "    user_id = int(g[\"user_id\"].iloc[0])\n",
    "    items = g[\"click_article_id\"].astype(int).tolist()\n",
    "\n",
    "    # seed \"naturel\" en session-based: dernier clic connu (avant le true_next)\n",
    "    seed_id = int(items[-2])\n",
    "\n",
    "    recs = recommend_lightfm(user_id, TOP_K)  # LightFM user-based\n",
    "    rows.append({\n",
    "        \"session_id\": int(sid),\n",
    "        \"user_id\": user_id,\n",
    "        \"seed_id\": seed_id,\n",
    "        \"internal_cosine\": coherence_internal(recs),\n",
    "        \"seed_cosine\": coherence_to_seed(seed_id, recs),\n",
    "        \"emb_coverage\": sum(int(int(a) in article_id_to_eidx) for a in recs) / len(recs),\n",
    "    })\n",
    "\n",
    "    checked += 1\n",
    "    if checked >= MAX_SESSIONS:\n",
    "        break\n",
    "\n",
    "df_coh = pd.DataFrame(rows)\n",
    "\n",
    "print(\"sessions checked:\", len(df_coh))\n",
    "display(df_coh[[\"internal_cosine\", \"seed_cosine\", \"emb_coverage\"]].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8a4ef-d841-4547-bd6c-412ff7712940",
   "metadata": {},
   "source": [
    "## Interprétation des scores de cohérence (LightFM)\n",
    "\n",
    "On mesure ici deux choses avec la similarité cosine des embeddings :\n",
    "\n",
    "- **seed_cosine** : cohérence des 5 recommandations *par rapport au contexte* (l’article “seed”, ici le dernier clic connu avant le clic cible).\n",
    "- **internal_cosine** : cohérence *entre les 5 recommandations elles-mêmes* (moyenne des cosines sur toutes les paires du top-5).\n",
    "- **emb_coverage** : part des recommandations qui ont bien un embedding (ici 1.0 ⇒ mesure fiable).\n",
    "\n",
    "### Résultats observés (300 sessions)\n",
    "- **emb_coverage = 1.0** : toutes les recommandations ont un embedding, donc les cosines sont calculables partout.\n",
    "- **seed_cosine ~ 0.34 (médiane ~ 0.29)** : cohérence *modérée* avec l’article seed.\n",
    "  - 25% des sessions ont une cohérence < ~0.25 (faible)\n",
    "  - 25% ont une cohérence > ~0.46 (bonne)\n",
    "  - un minimum négatif (≈ -0.17) indique que, parfois, une partie des recos est clairement “hors thème” par rapport au seed.\n",
    "  - Interprétation : LightFM est plutôt **user-profil** (goûts globaux) ; il peut donc recommander des contenus cohérents avec l’utilisateur, mais pas toujours alignés avec l’intention immédiate de la session.\n",
    "- **internal_cosine ~ 0.35** : les 5 recommandations sont globalement **modérément homogènes entre elles** (liste “thématique” sans être extrêmement répétitive).\n",
    "  - min ~0.25 : parfois une liste plus variée\n",
    "  - max ~0.83 : parfois une liste très homogène (quasi “même sujet”)\n",
    "\n",
    "### Point d’attention : quartiles identiques sur `internal_cosine`\n",
    "Le fait que 25% / 50% / 75% soient identiques (≈ 0.324444) suggère une forte répétition de valeurs, ce qui peut arriver si :\n",
    "- LightFM produit très souvent des listes proches (effet “concentration” sur un petit ensemble d’items),\n",
    "- ou si les embeddings induisent des similarités très proches pour des groupes d’articles.\n",
    "À vérifier si besoin en regardant la fréquence des articles recommandés (diversité / concentration).\n",
    "\n",
    "### Conclusion pratique (qualité “liste”)\n",
    "- LightFM produit des listes **cohérentes entre elles** (internal_cosine OK).\n",
    "- L’alignement avec le contexte immédiat (seed) est **variable** (seed_cosine moyen avec quelques cas très faibles), ce qui est cohérent avec un modèle orienté “préférences utilisateur” plutôt que “session / intention instantanée”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3defa6-6e04-497a-a6da-326b740d47b1",
   "metadata": {},
   "source": [
    "## Préparation au déploiement : Export artefacts MVP (fichiers à mettre dans Blob)\n",
    "\n",
    "Objectif :\n",
    "- sauvegarder les artefacts minimaux nécessaires au serving “lookup-only”.\n",
    "- fichiers recommandés :\n",
    "  - `user_top5.parquet` : recommandations pré-calculées\n",
    "  - `trending.parquet` : fallback cold start\n",
    "  - (optionnel) `meta.json` : version/infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08cc972e-8268-44d8-9704-adaed530b713",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artefacts écrits dans: artifacts_lightfm\n",
      " - artifacts_lightfm/user_top5.parquet\n",
      " - artifacts_lightfm/trending.parquet\n",
      " - artifacts_lightfm/meta.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "ARTIFACTS_DIR = \"artifacts_lightfm\"\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "# Fichier principal: lookup top-5\n",
    "user_top5_path = os.path.join(ARTIFACTS_DIR, \"user_top5.parquet\")\n",
    "user_top5.to_parquet(user_top5_path, index=False)\n",
    "\n",
    "# Fallback trending\n",
    "trending_path = os.path.join(ARTIFACTS_DIR, \"trending.parquet\")\n",
    "trending.to_parquet(trending_path, index=False)\n",
    "\n",
    "# Petit méta (optionnel)\n",
    "meta = {\n",
    "    \"model\": \"LightFM_hybrid_embeddings\",\n",
    "    \"top_k\": TOP_K,\n",
    "    \"n_users\": int(len(user_top5)),\n",
    "    \"n_items\": int(n_items),\n",
    "    \"loss\": \"warp\",\n",
    "    \"no_components\": 32,\n",
    "    \"learning_rate\": 0.05,\n",
    "}\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"meta.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Artefacts écrits dans:\", ARTIFACTS_DIR)\n",
    "print(\" -\", user_top5_path)\n",
    "print(\" -\", trending_path)\n",
    "print(\" -\", os.path.join(ARTIFACTS_DIR, \"meta.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e78bba3-d29a-4440-a3b0-d93a123d96c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([162369, 161178, 156355, 158888, 156718], 'lightfm_precomputed')\n",
      "([272660, 207122, 161178, 284463, 160474], 'trending')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exemple de logique \"serving\" en local (identique côté Azure Function)\n",
    "\n",
    "user_top5_loaded = pd.read_parquet(user_top5_path)\n",
    "trending_loaded = pd.read_parquet(trending_path)\n",
    "\n",
    "top5_map = dict(zip(user_top5_loaded[\"user_id\"].astype(int), user_top5_loaded[\"recommended_articles\"]))\n",
    "trending_list = trending_loaded[\"article_id\"].astype(int).tolist()\n",
    "\n",
    "def recommend_serving_lookup(user_id: int, k: int = TOP_K) -> tuple[list[int], str]:\n",
    "    recos = top5_map.get(int(user_id))\n",
    "    if recos is None:\n",
    "        return trending_list[:k], \"trending\"\n",
    "    return list(recos)[:k], \"lightfm_precomputed\"\n",
    "\n",
    "# Test rapide\n",
    "print(recommend_serving_lookup(user_id=list(top5_map.keys())[0]))\n",
    "print(recommend_serving_lookup(user_id=-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892745ed-27b4-47c7-98d6-8b7066d22c73",
   "metadata": {},
   "source": [
    "## Serving en ligne (Azure Function) : charger le modèle et prédire à la demande\n",
    "\n",
    "Objectif :\n",
    "- **ne pas** pré-calculer par user,\n",
    "- **charger** les artefacts (modèle + matrices + mappings) au démarrage de la Function,\n",
    "- **inférer en ligne** : `GET /recommend?user_id=...` → renvoie 5 articles.\n",
    "\n",
    "Principe :\n",
    "- au *cold start*, on charge et on met en cache :\n",
    "  - le modèle LightFM,\n",
    "  - `item_features` (embeddings en sparse),\n",
    "  - les mappings (`user_to_idx`, `idx_to_item`, `user_seen`),\n",
    "  - `trending` (fallback).\n",
    "- à chaque requête :\n",
    "  - user connu → score + top-5\n",
    "  - user inconnu → trending\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92689f50-2cb5-41cc-a4f4-02f7ba3b1378",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artefacts exportés dans: artifacts_lightfm_online\n",
      " - artifacts_lightfm_online/lightfm_model.pkl\n",
      " - artifacts_lightfm_online/item_features.npz\n",
      " - artifacts_lightfm_online/mappings.pkl\n",
      " - artifacts_lightfm_online/trending.parquet\n",
      " - artifacts_lightfm_online/meta.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Export des artefacts pour le serving en ligne\n",
    "# On sauvegarde tout ce qui est nécessaire pour faire model.predict(...) côté Azure Function.\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "ARTIFACTS_DIR = \"artifacts_lightfm_online\"\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "# 1) Sauvegarde du modèle LightFM\n",
    "model_path = os.path.join(ARTIFACTS_DIR, \"lightfm_model.pkl\")\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(model, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# 2) Sauvegarde des item_features (embeddings) au format sparse .npz\n",
    "item_features_path = os.path.join(ARTIFACTS_DIR, \"item_features.npz\")\n",
    "save_npz(item_features_path, item_features)\n",
    "\n",
    "# 3) Sauvegarde des mappings indispensables au serving\n",
    "# - user_to_idx: user_id réel -> index LightFM\n",
    "# - idx_to_item: index LightFM -> article_id réel\n",
    "# - user_seen: articles vus par user (pour filtrer les recos déjà vues)\n",
    "mappings = {\n",
    "    \"user_to_idx\": user_to_idx,\n",
    "    \"idx_to_item\": idx_to_item,\n",
    "    \"user_seen\": user_seen,\n",
    "    \"top_k\": TOP_K,\n",
    "}\n",
    "mappings_path = os.path.join(ARTIFACTS_DIR, \"mappings.pkl\")\n",
    "with open(mappings_path, \"wb\") as f:\n",
    "    pickle.dump(mappings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# 4) Trending (fallback cold start user)\n",
    "trending_path = os.path.join(ARTIFACTS_DIR, \"trending.parquet\")\n",
    "trending.to_parquet(trending_path, index=False)\n",
    "\n",
    "# 5) Meta (optionnel mais utile pour debug/traçabilité)\n",
    "meta = {\n",
    "    \"model\": \"LightFM_online\",\n",
    "    \"loss\": \"warp\",\n",
    "    \"no_components\": 32,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_users\": int(len(user_to_idx)),\n",
    "    \"n_items\": int(n_items),\n",
    "    \"top_k\": int(TOP_K),\n",
    "}\n",
    "meta_path = os.path.join(ARTIFACTS_DIR, \"meta.json\")\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Artefacts exportés dans:\", ARTIFACTS_DIR)\n",
    "print(\" -\", model_path)\n",
    "print(\" -\", item_features_path)\n",
    "print(\" -\", mappings_path)\n",
    "print(\" -\", trending_path)\n",
    "print(\" -\", meta_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a655561-16c8-4ff2-bfa6-13435a1c9ea8",
   "metadata": {},
   "source": [
    "## Test local “comme en prod” (charger les artefacts et prédire)\n",
    "\n",
    "Objectif :\n",
    "- simuler exactement ce que fera l’Azure Function :\n",
    "  - charger modèle + matrices + mappings,\n",
    "  - répondre à un `user_id` en renvoyant 5 articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86d84c60-ad4f-4269-955a-ce98c5951dae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User connu: 0 ([162369, 161178, 156355, 158888, 156718], 'lightfm_online')\n",
      "User inconnu: -1 ([272660, 207122, 161178, 284463, 160474], 'trending')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test local du serving en ligne (chargement depuis disque)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# --- Chargement artefacts\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model_loaded = pickle.load(f)\n",
    "\n",
    "item_features_loaded = load_npz(item_features_path)\n",
    "\n",
    "with open(mappings_path, \"rb\") as f:\n",
    "    m_loaded = pickle.load(f)\n",
    "\n",
    "user_to_idx_loaded = m_loaded[\"user_to_idx\"]\n",
    "idx_to_item_loaded = m_loaded[\"idx_to_item\"]\n",
    "user_seen_loaded = m_loaded[\"user_seen\"]\n",
    "TOP_K_LOADED = m_loaded[\"top_k\"]\n",
    "\n",
    "trending_loaded = pd.read_parquet(trending_path)\n",
    "TRENDING_LIST_LOADED = trending_loaded[\"article_id\"].astype(int).tolist()\n",
    "\n",
    "# --- Pré-calcul utile\n",
    "n_items_loaded = item_features_loaded.shape[0]\n",
    "all_item_idx_loaded = np.arange(n_items_loaded, dtype=np.int32)\n",
    "\n",
    "# --- Fonction: recommander en ligne\n",
    "def recommend_online(user_id: int, k: int = TOP_K_LOADED) -> tuple[list[int], str]:\n",
    "    \"\"\"\n",
    "    Reco online:\n",
    "    - user inconnu -> trending\n",
    "    - user connu -> scores LightFM + filtrage 'seen' + fallback trending\n",
    "    \"\"\"\n",
    "    if user_id not in user_to_idx_loaded:\n",
    "        return TRENDING_LIST_LOADED[:k], \"trending\"\n",
    "\n",
    "    uidx = user_to_idx_loaded[user_id]\n",
    "    scores = model_loaded.predict(uidx, all_item_idx_loaded, item_features=item_features_loaded)\n",
    "\n",
    "    # On prend plus de candidats que k pour pouvoir filtrer les items déjà vus\n",
    "    candidate_n = min(len(scores), k * 50)\n",
    "    top_idx = np.argpartition(-scores, candidate_n)[:candidate_n]\n",
    "    top_idx = top_idx[np.argsort(-scores[top_idx])]\n",
    "\n",
    "    seen = set(user_seen_loaded.get(user_id, []))\n",
    "    recs = []\n",
    "\n",
    "    for ii in top_idx:\n",
    "        aid = idx_to_item_loaded[int(ii)]\n",
    "        if aid in seen:\n",
    "            continue\n",
    "        recs.append(int(aid))\n",
    "        if len(recs) >= k:\n",
    "            break\n",
    "\n",
    "    # Complète avec trending si besoin\n",
    "    if len(recs) < k:\n",
    "        for aid in TRENDING_LIST_LOADED:\n",
    "            if aid not in seen and aid not in recs:\n",
    "                recs.append(int(aid))\n",
    "            if len(recs) >= k:\n",
    "                break\n",
    "\n",
    "    return recs, \"lightfm_online\"\n",
    "\n",
    "# Test rapide\n",
    "some_user = next(iter(user_to_idx_loaded.keys()))\n",
    "print(\"User connu:\", some_user, recommend_online(some_user))\n",
    "print(\"User inconnu:\", -1, recommend_online(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd68dfe-2286-4ed2-a6b8-aa5823421701",
   "metadata": {},
   "source": [
    "# Déploiement MVP en ligne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22264386-5ca2-477c-a6d5-9d95f350b4cf",
   "metadata": {},
   "source": [
    "## Azure Function minimale (HTTP) — fichiers à créer\n",
    "\n",
    "Objectif :\n",
    "- exposer un endpoint :\n",
    "  - `GET /api/recommend?user_id=123`\n",
    "- charger les artefacts une seule fois (cache global),\n",
    "- renvoyer un JSON : `{ user_id, recommended_articles, strategy }`.\n",
    "\n",
    "Hypothèse MVP :\n",
    "- les artefacts sont présents sur le filesystem de la Function (déploiement simple),\n",
    "  ou montés / téléchargés depuis Blob (à ajouter ensuite).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb07842-9ed2-466f-b329-9d028dd4a2d8",
   "metadata": {},
   "source": [
    "## Notes déploiement (MVP)\n",
    "\n",
    "- Déposer le dossier `artifacts_lightfm_online/` à côté de la Function (ou le copier dans le package).\n",
    "- Définir la variable d’environnement `ARTIFACTS_DIR` si besoin.\n",
    "- Exemple d’appel :\n",
    "  - `GET https://<ton-host>/api/recommend?user_id=123`\n",
    "  - (optionnel) `&k=5`\n",
    "\n",
    "Dépendances (requirements.txt) à prévoir pour Azure Functions :\n",
    "- `azure-functions`\n",
    "- `pandas`\n",
    "- `numpy`\n",
    "- `scipy`\n",
    "- `lightfm`\n",
    "- `pyarrow` (si tu lis/écris du parquet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab874028-0b33-414e-901e-61f2e9863ad4",
   "metadata": {},
   "source": [
    "## Mesurer les temps (MVP) : chargement des artefacts + inférence\n",
    "\n",
    "Objectif :\n",
    "- estimer le coût du *cold start* (temps pour charger modèle + matrices + mappings),\n",
    "- estimer le coût d’une requête *warm* (temps pour scorer + extraire top-5),\n",
    "- avoir une idée du risque de latence en Azure Functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10e56670-8f13-4507-b879-a58a869d0348",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps de chargement artefacts (cold start simulé): 0.186 s\n",
      "user_id=0 | mean=9.32 ms | p95=10.43 ms | max=10.83 ms\n",
      "user_id=-1 | mean=0.00 ms | p95=0.00 ms | max=0.00 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# --- Bloc 1: mesure du temps de chargement (simule un cold start)\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model_loaded = pickle.load(f)\n",
    "\n",
    "item_features_loaded = load_npz(item_features_path)\n",
    "\n",
    "with open(mappings_path, \"rb\") as f:\n",
    "    m_loaded = pickle.load(f)\n",
    "\n",
    "user_to_idx_loaded = m_loaded[\"user_to_idx\"]\n",
    "idx_to_item_loaded = m_loaded[\"idx_to_item\"]\n",
    "user_seen_loaded = m_loaded[\"user_seen\"]\n",
    "TOP_K_LOADED = int(m_loaded.get(\"top_k\", TOP_K))\n",
    "\n",
    "trending_loaded = pd.read_parquet(trending_path)\n",
    "TRENDING_LIST_LOADED = trending_loaded[\"article_id\"].astype(int).tolist()\n",
    "\n",
    "n_items_loaded = item_features_loaded.shape[0]\n",
    "all_item_idx_loaded = np.arange(n_items_loaded, dtype=np.int32)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(f\"Temps de chargement artefacts (cold start simulé): {(t1 - t0):.3f} s\")\n",
    "\n",
    "\n",
    "# --- Bloc 2: fonction de recommandation (identique au serving)\n",
    "def recommend_online(user_id: int, k: int = TOP_K_LOADED) -> tuple[list[int], str]:\n",
    "    # Cold start user\n",
    "    if user_id not in user_to_idx_loaded:\n",
    "        return TRENDING_LIST_LOADED[:k], \"trending\"\n",
    "\n",
    "    uidx = user_to_idx_loaded[user_id]\n",
    "    scores = model_loaded.predict(uidx, all_item_idx_loaded, item_features=item_features_loaded)\n",
    "\n",
    "    # Sur-échantillonne pour filtrer les items déjà vus\n",
    "    candidate_n = min(len(scores), k * 50)\n",
    "    top_idx = np.argpartition(-scores, candidate_n)[:candidate_n]\n",
    "    top_idx = top_idx[np.argsort(-scores[top_idx])]\n",
    "\n",
    "    seen = set(user_seen_loaded.get(user_id, []))\n",
    "    recs = []\n",
    "\n",
    "    for ii in top_idx:\n",
    "        aid = idx_to_item_loaded[int(ii)]\n",
    "        if aid in seen:\n",
    "            continue\n",
    "        recs.append(int(aid))\n",
    "        if len(recs) >= k:\n",
    "            break\n",
    "\n",
    "    # Complète si besoin\n",
    "    if len(recs) < k:\n",
    "        for aid in TRENDING_LIST_LOADED:\n",
    "            if aid not in seen and aid not in recs:\n",
    "                recs.append(int(aid))\n",
    "            if len(recs) >= k:\n",
    "                break\n",
    "\n",
    "    return recs, \"lightfm_online\"\n",
    "\n",
    "\n",
    "# --- Bloc 3: mesure du temps d'inférence (warm)\n",
    "# On teste sur 1 user connu (si possible) et sur un user inconnu.\n",
    "known_user = next(iter(user_to_idx_loaded.keys()))\n",
    "unknown_user = -1\n",
    "\n",
    "def time_inference(user_id: int, n_runs: int = 20):\n",
    "    # Petit warm-up (premier appel peut être plus lent)\n",
    "    recommend_online(user_id)\n",
    "\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        t0 = time.perf_counter()\n",
    "        _ = recommend_online(user_id)\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "\n",
    "    times = np.array(times)\n",
    "    print(f\"user_id={user_id} | mean={times.mean()*1000:.2f} ms | p95={np.percentile(times,95)*1000:.2f} ms | max={times.max()*1000:.2f} ms\")\n",
    "\n",
    "time_inference(known_user, n_runs=30)\n",
    "time_inference(unknown_user, n_runs=30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
